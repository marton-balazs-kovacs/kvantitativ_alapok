[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kvantitatív Alapok",
    "section": "",
    "text": "Előszó\nEz a jegyzet a Neumann János Egyetem és az MNB Intézet által indított Nemzetközi Gazdaság és Gazdálkodás mesterszakának Kvantitatív alapok nevű tantárgyához készült. Célom a hallgatók felkészülését segíteni azzal, hogy egy helyen, átlátható formában közlöm a tantárgyhoz készült jegyzeteket, példákat, gyakorlatokat és ábrákat. A Kvantitatív alapok tantárgy felépítésénél nagyban merítettem Russ Poldrack Statistical Thinking for the 21st Century című munkájából, Nagy Tamás Adatelemzés és statisztikai következtetés nevű órai jegyzeteiből és Andy Field statisztika tankönyveiből. Ha az olvasó ezen művekből ismerős gondolatokat, példákat vagy magyarázatokat lát, akkor azok nagy valószínűséggel onnan is lettek átvéve. Én magam is nagyrészt tőlük tanultam azt, amit a kvantitatív elemzésről tudok. Ez a három ember nálam sokkal többet gondolkozott azon, hogyan kell hatékony módon statisztikát tanítani egyetemista hallgatóknak, így nem láttam értelmét, hogy a tantárgy felépítését a nulláról kezdjem. Ezúton is szeretném megköszönni a segítségük!\n\n\nKöszönetnyílvánítás\nSzeretnék továbbá köszönetet mondani Ignits Györgyinek, Kapitány Balázsnak, Szászi Barnabásnak, Hajdú Nándornak, Bognár Miklósnak és Szécsi Péternek, akik példa adatok megosztásán és jótanácsokon keresztül segítették a jegyzet létrejöttét."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Bevezetés",
    "section": "",
    "text": "A kvantitatív elemzés nem az adatoknál kezdődik. Az eddigi oktatói tapasztalataim alapján amikor egy hallgató elakad egy önálló elemzési feladat során az nem azért van mert helytelenül magolta be az éppen alkalmazott statisztikai teszt előfeltételeit, vagy mert nem tudja a standard hiba képletét. Ezekre a kérdésekre egy gyors Google kereséssel könnyen meg lehet találni a választ.\n\nHanem mert nem látja át az empirikus tudományos módszer egészét, annak lépéseit és összefüggéseit\n\nNincs jól megfogalmazott hipotézis\nNem feltett kutatási kérdés megválaszolásához szükséges mérőeszközöket használtak\nNem látják át a rosszul strukturált adattáblát\nNem értik a frekventista hipotézis tesztelés működését\nÉs csak ezután jön, hogy nem értik milyen statisztikai eljárást kell alkalmazni és azt hogyan\nEzzel a lépéssel kapcsolatban én is gyakran teszek fel kérdéseket kollégáknak és az internetnek (és bíztatok mindenkit, hogy tegyen ugyanígy)"
  },
  {
    "objectID": "scientific_method.html#a-tudomány-célja",
    "href": "scientific_method.html#a-tudomány-célja",
    "title": "1  Tudományos módszer",
    "section": "1.1 A tudomány célja",
    "text": "1.1 A tudomány célja\n\nA tudomány célja, hogy általános magyarázotokkal szolgáljon a minket körülvevő világról\nA tudományos magyarázatok leegyszerüsített formában írják le a valóságot\nA tudományos magyarázatok segítségével így képesek vagyunk\n\njól informált döntéseket hozni\npredikciókat alkotni új helyzetekre a már meglévő tudásunk alapján\n\nKésőbb majd látni fogjuk, hogy a kutatási folyamat sok pontján félrecsúszhat az, hogy a kutatásunk alapján megbízható döntéseket hozzunk vagy predikciókat alkossunk\nA tudományos megközelítés azonban nem az egyetlen mód, amelyen keresztül a valóságot magyarázzuk\nMiben más, mint egyéb megismerési módok?\n\nPl: vallás: autoritás alapú\nKritikai megközelítés\nTesztelhető (falszifikálható hipotézisek"
  },
  {
    "objectID": "scientific_method.html#az-empirikus-tudományos-folyamat-lépései",
    "href": "scientific_method.html#az-empirikus-tudományos-folyamat-lépései",
    "title": "1  Tudományos módszer",
    "section": "1.2 Az empirikus tudományos folyamat lépései",
    "text": "1.2 Az empirikus tudományos folyamat lépései\n\nÁltalános kérdésfelvetés\n\nEz talán a legegyszerűbb lépés, az ember kíváncsi természetű, szeretné érteni az őt körülvevő valóságot\n\nElmélet alkotás\n\nAhhoz, hogy egy kérdést meg tudjunk válaszolni empirikus módon egy elméletet kell alkotnunk a kérdés mögött álló lehetséges hatásmechanizmusról\nAz elmélet falszifikálható kell legyen\n\nTudunk olyan megfigyeléseket tenni amelyek fényében az elméletet elvetjük\n\nA jó elméletek\n\nElérés (reach): minél több jelenséget magyaráz meg egy elmélet annál jobb\nParszimónia: két versenyző elmélet közül az a jobb, ami kevesebb elemből áll\n\nLásd Occam borotvája\n\nKonzervatívizmus: Mennyire illeszkedik már meglévő tesztelt és elfogadott elméletekhez\n\n\nHipotézis alkotás\n\nA hipotézis az elméletünknek egy konkrétan tesztelhető operacionalizált része\nEgy elmélet alapján többféle hipotézist fel lehet állítani\nA hipotézis alapján predikciókat alkotunk, amelyeket tesztelünk\nEgy hipotézis bizonyításával nem bizonyítjuk az elméletet is!\nDe tudjuk a teszt eredményei által tovább finomítani az elméletet\nVagy elvetjük azt\nFontos, hogy a hipotézis valóban illeszkedjen az adott elmélethez\n\nKutatási elrendezés\n\nA hipotézis tesztelésére annak feltételezései alapján egy kutatást tervezünk\nA kutatás megtervezésénél számos különböző módszertan közül tudunk választani\nMindegyiknek vannak előnyei és hátránya, a hipotézis és az elérhető erőforrások fényében választunk közülük\n\nKérdőíves\nMegfigyeléses\nKísérleti\n\nVan pár általános szempont, amelyeket módszertantól függetlenül figyelembe kell vennünk és amelyek befolyásolják az eredményekből levontható következtetéseket\n\nMinta felépítése és mintaméret\nMérőeszköz és annak pontossága, megbízhatósága, validitása és granularitása\n\nAhhoz hogy oksági viszonyt feltételezzünk két jelenség közt nem feletkezhetünk meg az adatgyűjtés módjáról\nMegfigyeléses vizsgálatoknál nem tudjuk biztosan kijelenteni hogy két változó között oksági viszony van\n\nLehetséges hogy egyébb faktorok befolyásolják a kapott együttjárást\nhttps://www.tylervigen.com/spurious-correlations\n\nEzért a kutatók általában az oksági viszony meghatározásához kísérleti kutatási elrendezést használnak (pl: randomized control trial)\n\nA lehetséges, de nem viszgált befolyásoló faktorokat random mintavételezés útján zárják ki az adatgyűjtés során\n\nVannak statisztikai módszerek amivel utólag is kontrollálni tudjuk ezeket a változókat, de sokkal nehezebb ezt utólag megtenni\nEz is kiemeli a jól megtervezett kutatások és részletesen kidolgozott elméletek fontosságát!\nMintavételezés\n\nAz esetek kis részében tudjuk az egész populációt vizsgálni\nMinták tesztelésén keresztül vonunk le általános következtetéseket\nDe mekkora mintára van szükség ahhoz, hogy a populációra tudjunk következtetni?\n\n\nAdatok feldolgozása\n\nÁltalában nem szokták külön lépésként kezelni, de az óra témaja és az eredményekre gyakorolt lehetséges hatása miatt fontos megemlíteni\nA kapott adatokat befolyásolja az általunk választott kutatási elrendezés és az adatgyűjtés során fellépő váratlan torzító tényezők\nNagyon ritka esetben készek az adatgyűjtés után az adatok az elemzésre\nÁltalában először adat rendezést és adattisztítást kell elvégeznünk\n\nStatisztikai elemzés\n\nAz elemzés során használhatunk\n\nLeíró statisztikai eljárásokat\nKövetkeztetéses statisztikai eljárásokat\n\nRengeteg statisztikai eljárás van, a statisztikusok most is dolgoznak újak kifejlesztésén és validációján\nAz, hogy milyen eljárást választunk függ a hipotézisünktől, a kutatási elrendezésünktől, és az adatgyűjtés során kapott adatoktól\nTöbbféle lehetséges valid elemzési út is létezik\n\nLást: multi-analyst study\n\n\nEredmények értelmezése\n\nA statisztikai elemzés eredményeinek értelmezésére a tudományos folyamat összes eddigi lépése kihat\nKutatóként szeretnénk egyértelmű válaszokat kapni az általunk feltett kérdésekre\n\nSajnos nagyon kevés esetben ez a helyzet\nEz részben a tudományos folyamat összetettségének az eredménye\nRészben ennek a vágynak is szerepe van a p-értékek abuzálásában\nEgy kutatásból nagyon ritkán kapunk egyértelmű válaszokat\n\nLásd: metaanalízis, szisztematikus összefoglaló (systematic review)\n\n\nPár példa helyzet arra, amikor a tudományos módszer összetettsége árnyalja a statisztikai elemzés eredményeinek értelmezését:\n\nA választott mérőeszközök valójában nem a vizsgált konstruktumot mérik\nA minta milyensége vagy mérete nem indokolja az eredmények általánosítását\nAz adattisztítás során olyan megfigyelések is bent maradtak, amelyek szisztematikusan torzítják az eredményeket\n\nAz értelmezést korlázotó tényezőkről általában a tudományos publikáció limitációk szakaszában számolunk be"
  },
  {
    "objectID": "scientific_method.html#a-statisztika-szerepe-a-tudományban",
    "href": "scientific_method.html#a-statisztika-szerepe-a-tudományban",
    "title": "1  Tudományos módszer",
    "section": "1.3 A statisztika szerepe a tudományban",
    "text": "1.3 A statisztika szerepe a tudományban\n\nA komplex valóság egyszerüsített leírása, ami egyúttal azt is elmondja mennyire lehetünk bizonytalanok ebben a tudásban\nMiért van szükség a statisztikára?\n\nHeurisztikák veszélye\n\nPélda: USA bűnelkövetések gyakorisága\n\nSokkal gyakoribbnak gondoljuk a bűnelkövetések számát, mint amilyen gyakoriak a valóságban\nElérhetőségi torzítás (kognitív torzítás egyik fajtája)\nMédia szerepe?\n\n\nStatisztika segít abban hogy tanuljunk az adatokból\n\nHogyan frissítsük előzetes tudásunk az új adatok fényében\n\n\nA statisztika az adatösszesítésről szól\n\nHogyan tudunk úgy leegyszerüsíteni befogadhatatlan mennyiségű megfigyelést, hogy azok segítségével hipotézisünk tesztelni tudjuk, de fontos információ ne vesszen el\n\nA statisztika a bizonytalanság kezeléséről szól\n\nA világ összetett\nA legtöbb összetett jelenséget nehéz determinisztikus módon megmagyarázni\nBár tudunk ok-okozati kapcsolatot felállítani bizonyos összefüggések között általában ezek nem determinisztikus, hanem probabilisztikus predikciókhoz vezetnek\n\nLásd: dohányzás és tüdőrák\n\nTudjuk, hogy a dohányzás növeli a tüdőrák esélyét, azonban nem lehet biztosra mondani, hogyha valaki dohányzik, akkor mindenképp tüdőrákos is lesz\n\n\nA statisztika nem tud bizonyítani (úgy ahogy a matematika tud)\n\nHanem evidenciát tud felmutatni egy hipotézis mellett az eddigi megfigyelések fényében, de a bizonytalanságot nem tudjuk nullára csökkenteni\n\n\nA statisztika a kompromisszomkról szól\n\nNincs egyetlen objektív módszer a statisztikában\nA kutató egy kutatás megtervezése során rengeteg olyan döntési helyzettel találkozik, ahol nincs objektíven helyes döntés\nAzt, hogy melyik útat választja azonban komoly hatással lehet a kutatásból levont következtetésekre\n\nA döntési pontokat sokszor a kutatói szabadságfok fogalmával írjuk le\n\nLásd: Wicherts et al. (2016)\n\n\nMindig a vizsgált kérdés, az adatgyűjtést és elemzést korlátozó tényezők függvényében kell megtalálnunk a legmeggyőzőbb elemzési utat\n\nAhhoz, hogy a választott elemzési út ténylegesen meggyőző legyen transzparensen közölnünk kell analitikus döntéséinket és a mellette szóló érveket\nEz az alapfeltétele az analitikus megismételhetőségnek: más kutató ugyanazokat az adatokat vizsgálva megegyező analatikus úton ugyanarra az eredményre érkezik\n\nEz sajnos ma a tudományban nem magától értetődő!\nLásd: Hardwicke et al. (2021)\n\n\nTöbb valid elemzési út is lehet ugyanannak a kérdésnek a vizsgálatára\n\nA szakmai közösség feladata ezeknek a felülbírálata\nLásd: multi analyst kutatások\n\n\n\n\n\n\n\nHardwicke, Tom E., Manuel Bohn, Kyle MacDonald, Emily Hembacher, Michèle B. Nuijten, Benjamin N. Peloquin, Benjamin E. DeMayo, Bria Long, Erica J. Yoon, and Michael C. Frank. 2021. “Analytic Reproducibility in Articles Receiving Open Data Badges at the Journal Psychological Science: An Observational Study.” Royal Society Open Science 8 (1): 201494.\n\n\nWicherts, Jelte M., Coosje LS Veldkamp, Hilde EM Augusteijn, Marjan Bakker, Robbie Van Aert, and Marcel ALM Van Assen. 2016. “Degrees of Freedom in Planning, Running, Analyzing, and Reporting Psychological Studies: A Checklist to Avoid p-Hacking.” Frontiers in Psychology, 1832."
  },
  {
    "objectID": "data.html#mi-az-adat",
    "href": "data.html#mi-az-adat",
    "title": "2  Adat",
    "section": "2.1 Mi az adat?",
    "text": "2.1 Mi az adat?\n\nAz adat változók összessége, amelyek valamilyen mérés eredményét rögzítik\n\nAz adat, angolul data többesszám, egyesszámban datum\n\nTehát data are és nem data is!\n\n\nSokszor gondolunk az adatra, mint egy adott, önmagában létező dologra. Ezzel szemben, az adat egy dolog mérés által létrejött reprezentációja\n\nTehát a mérés módja befolyásolja az adatok jelentését és minőségét\nIlletve a mérés befolyásolja az adatokból levont következtetéseket is\nIsmerhetünk akárhány statisztikai trükköt az adatok tisztítására, transzformálására, összesítésére, ha azok zajos, torzított, hibás mérésből származnak az adatokból statisztika útján levont következtetések is torzítani fognak\nEzért fontos már a kutatás megtervezésekor nagyon odafigyelni mit mérünk és milyen pontosságal tudjuk mérni.\nAz adatok létrejöttével a kutatásmódszertan foglalkozik\nLásd: Figure 2.1\nTovábbi olvasmányok:\n\nFried and Flake (2018)\nFlake and Fried (2020)\n\n\nMinden változónak legalább két különböző értéke kell legyen, hogy változónak nevezzük, különben egy konstans lenne\nA változóknak különböző típusai lehetnek, annak fényében milyen mérés eredményeit rögzítik\n\n\n\n\n\n\nFigure 2.1: Mars Climate Orbiter 1999-ben a Mars atmoszférájába lépve darabokra hullott, mert két modulja közt a kommunikáció kudarcot vallot. Ennek oka, hogy az egyik modulja angolszász mértékegységeket használt, míg a másik metrikusat. Forrás: http://www.vitalstatistics.info/uploads/mars%20climate%20orbiter.jpg"
  },
  {
    "objectID": "data.html#hogyan-keletkeznek-az-adatok",
    "href": "data.html#hogyan-keletkeznek-az-adatok",
    "title": "2  Adat",
    "section": "2.2 Hogyan keletkeznek az adatok?",
    "text": "2.2 Hogyan keletkeznek az adatok?\n\n2.2.1 Mit mérünk?\n\nElméleti konstruktumok vagy valós fizikai tulajdonságok\n\nSok esetben, főleg a viselkedéses közgazdaságtanban nem fizikai tulajdonságokat mérünk, hanem közvetlenül meg nem figyelhető élméleti konstruktumokat\n\nPl: boldogság\n\n\nAz elméleti konstruktumok mérésénél fontos, hogy hogyan operacionalizáljuk azok mérését\n\nBoldogság: mosolyok száma egy nap alatt vagy önbevallásos kérdőív 1-től 7-ig terjedő skáláján adott pontok\n\nValiditás (érvényesség)\n\nAzt mutatja meg, hogy mennyire mérjük azt, amit valójában mérni akarunk\nTöbbféle validitás mutató is van\n\nLátszatérvényesség\n\nElső ránézésre úgy tűnik-e, hogy a mérőeszközünk azt méri, amit mérni akarunk\nPl: vérnyomást a nyelv pirossága mentén szeretném megmérni valószínűleg a mérőeszközöm nem érvény adatokat fog adni\n\nKonstruktum validitás\n\nKét része van:\n\nKonvergens validitás\n\nA mérőeszköz mérései pozitív együttjárást mutatnak ugyanazt a konstruktumot vizsgáló más mérőeszközök méréseivel\n\nPl: boldogságot vizsgálom kérdőíves és interjú módszerrel is, az eredmények között pozitív kapcsolatot várok el\n\n\nDivergens validitás\n\nA mérőeszköz mérései és más mérőeszközök mérései között valóban nincs kapcsolat, ha elméleti szinten nem feltételezünk kapcsolatot a két vizsgált konstruktum között\n\n\nÚj mérőeszköz fejlesztése esetén általában már validált, a szakmában elfogadott mérőeszközökhöz hasonlítunk\n\nPrediktív validitás\n\nA mérőeszközünk mérései alapján előre tudunk jelezni más, a mért dologgal összefüggő egyéb kimeneteleket\n\nPl: ha feltételezzük, hogy a figyelmetlenség összefügg a pénzszórással, akkor azt várjuk, hogy aki a figyelmetlenségi kérdőíven magas pontszámot ér el, átlagosan jobban fogja szórni a pénzt a hétköznapokban\n\n\n\n\n\n\n\n2.2.2 Milyen pontossággal mérünk?\n\nMinden mérésben van mérési hiba\nÁltalában ezt akarjuk csökkenteni\nMegtehetjük:\n\nMérőeszköz minőségének javításával\nMég több méréssel\n\nMegbízhatóság (reliabilitás)\n\nAzt mutatja meg, hogy mennyire pontosan, konzisztensen mér a merőeszközünk\nTeszt-retesz megbízhatóság\n\nHa többször megismételjük a mérést, mennyire járnak együtt a mérések eredményei\n\nMegbízhatóság fontos, ha össze akarunk több mérést hasonlítani\n\nKét változó közötti kapcsolat nem lehet erősebb, mint egy változó és önmaga közötti kapcsolat (másnéven a változó megbízhatósága)\nNem megbízható mérés nem tud erős statisztikai összefüggésben lenni egy másik méréssel\n\n\n\n\n\n2.2.3 A változók mérési szintjei\n\nHogyan viszonyulnak egymáshoz a változó értékei\nFolytonos vagy diszkrét változók\n\nFolytonos: bármilyen értéket felvehet egy bizonyos értéktartományban\nDiszkrét: csak bizonyos értékeket vehet fel\n\nNégy szempont alapján térhetnek el:\n\nEgyediség: a változó minden értéke egyedi jelentéssel rendelkezik\nSorbarendezhetőség: sorba rendezhetők-e a változó értékei valamilyen szempont alapján\nEgyenlő távolság: az egyes értékek közötti távolság a skála minden pontján egyenlő\n\n1cm és 2cm között ugyanakkora a távolság, mint 12cm és 13cm között\n\nAbszolút nulla pont: van-e a skálának abszolút nulla pontja.\n\nPéldául súly vagy magasság\n\n\nEzek alapján a következő mérési szintekről beszélhetünk:\n\nNominális skála\n\nA skálának minden tagja egy egyedi értéket jelöl\nA skálában lévő számok kvalitatív értékek címkézésére vannak\nNem rakhatók nagyságrendileg sorrendbe, nincs nulla pontjuk, a köztük lévő távolság értelmezhetetlen\nMatematikai módszerek: összehasonlíthatók\nStatisztikai módszerek: módusz\nDiszkrét\nLegtöbbször az adattáblában egész számokkal vagy szöveggel jelöljük\n\nAz egész számok csak jelző címkeként szolgálnak, algebrai műveletek nem végezhetők rajtuk\n\n\nOrdinális skála\n\nÉrtékei egyediek és sorbarendezhetők\nDe az értékek közötti távolság értelmezhetetlen\nPl: fájdalom mérésére szolgáló skála\n\nA Likert-típusú skálánál például elmondható, hogy a “Teljesen egyetértek” pozitívabb, mint az “Inkább egyetértek”, de a kettő közti távolság nem kvantifikálható. Ezért nem tudunk Likert-típusú skáláknál átlagot számolni.\n\nMatematikai módszerek: megnézhetjük, hogy az egyik érték nagyobb-e a másiknál\nStatisztikai módszerek: medián\nDiszkrét\nAz adattáblában általában egész számokkal jelöljük őket\n\nIntervallum skála\n\nAz ordinális skálánál több, amennyiben a felvehető értékek közötti távolság állandó\nPl: hőfok Celsiusban\nMatematikai módszerek: összeadhatjuk vagy kivonhatjuk\nStatisztikai módszerek: átlag\nFolytonos\nAz adattáblában egyész számokkal vagy valós számokkal jelöljük őket\n\n Arány skála\n\nAz interval skálán felül van értelmezhető abszolút 0 pontja.\nPl: Súly és magasság\nMatematikai módszerek: szorozhatjuk vagy oszthatjuk\nStatisztikai módszerek: átlag\nFolytonos\nAz adattáblában egyész számokkal vagy valós számokkal jelöljük őket\n\n\n\n\n\n2.2.4 Mérési skálák hatása a statisztikai tesztek előfeltételeire\n\nA változók mérési szintjei meghatározzák, hogy milyen matematikai/statisztikai módszereket alkalmazhatunk rajtuk és így végül milyen kérdéseket tudunk általuk megválaszolni\nA változók mérési szintjei együtt járnak a mérési skálák granularitásával\n\nGranularitás: változó szintjeinek száma, azaz hány lehetséges értéket tud felvenni a változó\n\nPéldául a fájdalmat mérhetjük úgy, hogy:\n\nVizuális analóg skálánál a végpontok vannak megadva (nincs fájdalom - legerősebb elképzelhető fájdalom) közte 1-100-ig bejelölhetik a résztvevők az átélt fájdalmuk\nLikert-típusú skálán is mérhetjük, aminek három szintje van és mindegyik szinthez egy leíró címke tartozik (1 - egyáltalán nem fáj, 2- közepesen fáj, 3 - nagyon fáj)\nNumerikus skálán is mérhetjük, aminek 11 szintje (0 - 10) van az első ötödik és tizedik szinteken leíró címkével\n\nHa egy skála granularitása kicsi (<12) vagy minden szintjéhez címke tartozik, nem kezelhetjük intervallum skálaként\n\nTehát nem számolhatunk átlagot\n\nMérési skálák granularitását növelhetjük az itemek számával\n\nPl: Több 7 fokú válasz skálás kérdéssel mérjük ugyanazt a konstruktumot\n\nA válaszokat összesítjük (például összeadás vagy átlagolás útján)"
  },
  {
    "objectID": "data.html#hogyan-struktúráljuk-az-adatokat",
    "href": "data.html#hogyan-struktúráljuk-az-adatokat",
    "title": "2  Adat",
    "section": "2.3 Hogyan struktúráljuk az adatokat?",
    "text": "2.3 Hogyan struktúráljuk az adatokat?\n\nAz adatok különböző formátumban léteznek\n\nKérdőíves felmérések adatai, orvosi MRI képek, banki tranzakciók lenyomatai, twitter megosztások száma, egy adott időszakban megjelent publicisztikák\n\nA nyers adatok kinyerése és tisztítása teszi ki általában az adatelemzői munka nagy részét a statisztikai elemzéshez képest\nAz egyszerűség kedvéért az órán adattáblákkal fogunk dolgozni\nAz adattábla változók és megfigyelések összessége\n\nAdatpont (data point): egy mérésből származó érték, pl. egy ember egy válasza egy kérdésre\n\ncellák\n\nMegfigyelés (observation): ugyanannak a megfigyelési egységnek (pl. egy ember) az összes adatpontja (pl. összes kérdésre adott válasza)\n\nsorok\n\nVáltozó (variable): több megfigyelési egységnek az ugyanarra a mérésre adott értékei\n\nOszlopok\n\n\n\n\n2.3.1 Milyen egy jó adattábla?\n\n“négyzetes”: a sorok és oszlopok következetes módon megfigyeléseket és változókat jelentenek\nA változónevek emberi és gépi olvasásra is alkalmasak\n\nminél rövidebb, a változónevek mindig angolul, ékezetek nélkül, szóközök nélkül legyenek írva, legyen egyértelmű jelentésük, pl. education, bdi_1, bdi_sum\n\nVáltozónevek egy táblán belül következetesen legyenek használva\n\nLásd: snake_case vagy camelCase\nAzonos információ egységek azonos helyen legyenek elszeparálva\n\nquestion_01_item_01, question_01_item_02\nÉs nem: question01_item_01, question_01_item02\n\n\nA címkék szó szerint szerepelnek, és nem kódolva (pl. a kategorikus adatokhoz)\n\n“férfi”, és nem 1)\n\nA változó egy információt tartalmaz a megfigyelésről\n\n“Férfi 18-29” az két információ\n\nMinden információ explicit adat (és nem formázási mód vagy komment)\nA hiányzó adat hiányzó cella, nem pedig pl. -999\nMinden megfigyelési egységnek (pl. résztvevő) egyedi azonosítója van\nVan hozzá “kódkönyv” (code book vagy data dictionary)\n\nEz szintén legyen ember és gépi olvasásra alkalmas\nInformáció az adatok formátumáról (pl. adattábla x sorral és y változóval)\nVáltozók jelentése, mértékegysége, típusa, a változó hogyan lett kiszámítva\nInformáció az adatgyűjtés módszeréről\n\nVáltozón belül az értékek konzisztensen azonos típusúak és jelölésűek legyenek\n\nRossz példa: férfi, Férfi, nő, female\n\nFigyeljünk a kis és nagybetűkre!\nSzámozási sorrendnél használjunk vezető 0-át\n\nPl: 01, 02, 03, 11, 12\nÉs nem: 1, 11, 12, 2, 3"
  },
  {
    "objectID": "data.html#hogyan-dolgozzunk-az-adatokkal",
    "href": "data.html#hogyan-dolgozzunk-az-adatokkal",
    "title": "2  Adat",
    "section": "2.4 Hogyan dolgozzunk az adatokkal?",
    "text": "2.4 Hogyan dolgozzunk az adatokkal?\n\nAdatrendezés alapelvei\n\nNem törlünk ki adatokat\nAdatállomány feldolgozottsági szintjei szerinti felosztás\n\nSource: forrás adatok, ahogy a mérőeszközünk visszaadja az adatokat bármilyen beavatkozás nélkül, sokszor tartalmaz olyan adatokat, amelyek a résztvevők beazonosítását lehetővé teszik\n\na forrás adatok nyílt hozzáférésű megosztása ebben az esetben tilos\n\nRaw: nyers adatok, lényeges beavatkozás nem történt az adatfájlon, változó nevek lettek standardizálva, fájl formátuma lett megváltoztatva, a beazonosítást lehetővé tevő változók lettek maszkolva vagy kitörölve\nProcessed: feldolgozott adatok, az adatszűrés és szükséges transzformációk után\n\nNem módosítjuk az eredeti állományt, legfeljebb a másolato(ka)t\nHa lehet, készítsünk adatkezelési tervet (data management plan)\n\nSok pénzügyi támogató elvárja már!\nBiztosíthatjuk vele, hogy nem követünk el adatkezelési hibákat\nHogyan készítsünk jó adatkezelési tervet?\n\nLásd: Michener (2015)"
  },
  {
    "objectID": "data.html#adatkezelési-hibák",
    "href": "data.html#adatkezelési-hibák",
    "title": "2  Adat",
    "section": "2.5 Adatkezelési hibák",
    "text": "2.5 Adatkezelési hibák\n\nÁltalában arról hallunk a médiában, ha egy kutatót adahamisítással lepleznek le\nKevesebb szó esik az adatkezelési hibákról, pedig feltételezhetően ezek sokkal gyakrabban fordulnak elő\nAz adatkezelési hibákat sokszor akaratlanul követik el a kutatók\nAz adatkezelési hibáknak lehetnek súlyos következményei\n\nMegváltoztathatják például az adatokből levont köveztetéseket\n\nReinhart and Rogoff (2010) közgazdászok például a kimutatták, hogy egy állam valós gazdasági növekedése lelassul, ha az államtartozás a GDP 90%-át meghaladja\n\nEredményeik az USA költségvetési tervébe is bekerült\nKésőbb kiderült, hogy nem jelölték ki az összes adatsort az elemzés során, így a vizsgált adatoknak csak egy része került elemzésre\nAz újraelemzés az eredeti követeztetéseket invalidálta\n\nAz adatkezelési hibák nagy része az emberi hibából (human error) fakad\n\nKognitív kapacitásaink végesek, elfáradunk, nyomás alatt rosszabbul teljesítünk, stb.\n\nEzért fontos olyan adatkezelési rendszert kiépíteni, amely ezen hibák előfordulási valószínűségét csökkenti\nTovábbi olvasmányok:\n\nKovacs, Hoekstra, and Aczel (2021)\n\n\n\n\n\n\nFlake, Jessica Kay, and Eiko I Fried. 2020. “Measurement Schmeasurement: Questionable Measurement Practices and How to Avoid Them.” Advances in Methods and Practices in Psychological Science 3 (4): 456–65.\n\n\nFried, Eiko I., and Jessica K. Flake. 2018. “Measurement Matters.” APS Observer 31.\n\n\nKovacs, Marton, Rink Hoekstra, and Balazs Aczel. 2021. “The Role of Human Fallibility in Psychological Research: A Survey of Mistakes in Data Management.” Advances in Methods and Practices in Psychological Science 4 (4): 25152459211045930.\n\n\nMichener, William K. 2015. “Ten Simple Rules for Creating a Good Data Management Plan.” PLoS Computational Biology 11 (10): e1004525.\n\n\nReinhart, Carmen M, and Kenneth S Rogoff. 2010. “Growth in a Time of Debt.” American Economic Review 100 (2): 573–78."
  },
  {
    "objectID": "descriptive_statistics.html#értékek-eloszlása",
    "href": "descriptive_statistics.html#értékek-eloszlása",
    "title": "3  Leíró statisztika",
    "section": "3.1 Értékek eloszlása",
    "text": "3.1 Értékek eloszlása\n\nAz adatok leírásának egyik módja az eloszlásuk vizsgálata\n\nEz alapján meg tudjuk mondani, hogy mely értékek gyakoriak és melyek ritkák az adattáblánkban\n\nAz eloszlás megmondja, hogyan oszlik meg az adat a különböző lehetséges értékek között\n\nPéldául: diszkrét változó esetén hányan választották az egyes lehetséges opciókat\n\n\n\n3.1.1 Gyakorisági eloszlás\n\nA gyakorisági eloszlás megmondja, hogy egy változó lehetséges értékei milyen gyakran fordulnak elő a mintánkban\nDiszkrét változó gyakorisági eloszlása\n\nAz adatok abszolút gyakoriságát egy összesítő táblázatba is foglalhatjuk\nAhhoz, hogy meg tudjuk mondani a gyakoriságok között különbség valóban lényeges-e hasznos lehet megtekinteni a relatív frekvenciájukat (sűrűségüket)\nEhhez minden lehetséges értékhez el kell osztani az abszolút gyakoriságot a változóban található összes érték számával\n\nHogyan ábrázoljuk a gyakoriságot?\n\nDotplot\n\nMinden értéket egy pötty jelöl\nAz x tengely az értéktartomány\nAz y tengely a gyakoriság\nFolytonos változónál az összesítés során az értéktartományt különböző méretű “vödrökre” osztjuk\nMeghatározzuk a vödrök szélességét (binwidth)\nÉs az ebbe az értéktartományba eső értékek gyakoriságát számoljuk meg és ábrázoljuk\n\nA hisztogram hasonló, mint a dotplot\n\nDe az egyes értékek nem jelennek meg külön, így sok adat gyakoriságát egyszerre tudjuk ábrázolni\n\n\n\n\n3.1.1.1 A normál eloszlás\n\nA megfigyelt adatokban lévő változók eloszlását empirikus eloszlásnak nevezzük\nAzonban vannak nevezetes elméleti eloszlások, amelyknek a paramétereit már ismerjük (például a normál eloszlás)\nMivel ezen eloszlások paramétereit ismerjük, sokszor ezeket az eloszlásokat használjuk fel arra, hogy következtetéseket vonjunk le a populációra a mintánk alapján\nEnnek előfeltétele azonban, hogy a mintánkban lévő empirikus eloszlások kellőképp hasonlítsanak a nevezetes eloszlásokhoz\nAz elméleti normál eloszlásnak paraméterei\n\nEgy csúcsa van, az átlagnál, ami 0\nA szórása, ami az adatpontok átlag körüli szóródását jelöli 1\n\nLásd: Figure 3.1 (Field, Miles, and Field (2017))\n\nAz eloszlás szimmetrikus\n\nAz ettől való eltérést a ferdeséggel és csúcsossággal jelöljük\n\n\n\n\n\n\n\n\nFigure 3.1: Az ábrán két gyakorisági eloszlás látható amelyeknek átlaga megegyezik, de szórásuk különböző. Field, Miles, and Field (2017)\n\n\n\n\n\n\n3.1.1.2 Ferdeség és csúcsosság\n\nAz elméleti normál eloszlás ferdesége 0\nAz ettől való eltérés lehet pozitív és negatív irányú attól függően, hogy az eloszlás az X tengely mentén melyik irányba tolódik el\nHa a változónk ferdesége nagyobb 0-nál, akkor az eloszlás nem szimmetrikus, tehát eltér az elméleti normál eloszlástól\nLásd: Figure 3.2\nAz elméleti normál eloszlás csúcsossága 0\nAz empirikus eloszlásunk ehhez képest lehet csúcsos vagy lapos\nLásd: Figure 3.3\n\n\n\n\n\n\nFigure 3.2: Az ábrán két gyakorisági eloszlás látható különböző ferdeséggel. Hajdú Nándor ábrája.\n\n\n\n\n\n\n\n\n\nFigure 3.3: Az ábrán két gyakorisági eloszlás látható különböző csúcsossággal. Hajdú Nándor ábrája.\n\n\n\n\n\n\n3.1.1.3 Kumulatív gyakorisági eloszlás\n\nAzon értékek gyakorisága amelyek akkor vagy kevesebbek, mint az adott határérték, amit vizsgálunk\nKiszámolásához összeadjuk a hátárétrék gyakoriságát és az összes nála kisebb érték gyakoriságát\nÉrtéke soha nem csökkenhet"
  },
  {
    "objectID": "descriptive_statistics.html#statisztikai-modellek",
    "href": "descriptive_statistics.html#statisztikai-modellek",
    "title": "3  Leíró statisztika",
    "section": "3.2 Statisztikai modellek",
    "text": "3.2 Statisztikai modellek\n\nLeegyszerüsített reprezentációja az adatoknak\nLeírja az adatok struktúráját\nMindig van benne hiba faktor, kihagy részleteket\n\nLásd: Figure 3.4 (Field, Miles, and Field (2017))\n\n“All models are wrong but some are useful” (George Box)\nA statisztikai modellre gondolhatunk úgy is, mint egy elméletre, amely leírja hogyan keletkeztek az adatok\nCélunk: olyan modellt alkossunk, ami hatékonyan és pontosan írja le az adatok keletkezésének a módját\n\nMásszóval, fontos, hogy a modell jól illeszkedjen az adatokra\n\nMinél jobban illeszkedik a modell az adatokhoz (a valósághoz), annál megbízhatóbbak a modell által létrehozott predikciók\n\n\nMivel minden modell a valóság leegyszerüsítése, így az soha nem fogja tökéletesen reprezentálni a valóságot\n\nLesz hiba a modell által prediktált értékek és az egyes megfigyelések között\n\nAdat = modell + hiba\n\nModell: az értékek, amit az elméletünk alapján elvárunk\nHiba: a modell által prediktált értékek és a valós adatpontok közötti különbség\n\n\n\n\n\n\n\nFigure 3.4: Az építészetben is használnak modelleket arra, hogy bizonyos események bekövetkezését prediktálják általuk. Az ábrán több különböző modellt láthatunk egy hídra. A modell minél pontosabban írja le a valóságot annál jobb predikciókat lehet általa tenni arra, hogy a megépített híd megbírja-e majd az átmenő forgalmat.\n\n\n\n\n\n3.2.1 A legegyszerűbb statisztika modell, az átlag\n\nMinden megfigyelésre ugyanazt az értéket prediktálja\nPélda\n\nVizsgálhatjuk például, hogy a statisztika tanároknak hány barátja van\nTegyük fel, hogy 5 tanárt kérdezünk meg\nAz átlag: (1 + 2 + 3 + 3 + 4)/5 = 2.6\nEbből is látszik, hogy az átlag egy statisztikai modell, hiszen egy hipotetikus érték, nem megfigyelhető a valóságban\nLásd: Figure 3.5 (Field, Miles, and Field (2017))\n\n\n\n\n\n\n\nFigure 3.5: Az ábrán az öt megkérdezett statisztika oktatóhoz tartozó adatok láthatók és az átlag. Az X tengely az egyes statisztika oktatókat jelöli, míg az Y tengely az oktatók barátainak a számát. Az X tengellyel párhuzamos vonal az átlag. Az átlag által prediktált értékek és a valós értékek közti különbséget a szaggatott vonalak jelölik. Ez a hiba.\n\n\n\n\n\n\n3.2.2 Modell illeszkedésének a vizsgálata\n\nHogyan tudjuk megvizsgálni, hogy mennyire jól illeszkedik az átlag, mint modell, az adatokra?\n\nAhhoz, hogy eldöntsük a modell jól írja-e le az adatokat, megnézhetjük a megfigyelt adatok és a modell értékei közötti különbséget\nEzen értékek közötti eltérés a modell hibája\nPéldául annál a kutatónál, akinek egy barátja van, a modell 2.6 barátot prediktál (ez volt az átlag), a modell hibája, azaz az eltérés, így megfigyelt értél - prediktált érték = -1.6\nEbben az esetben a modell felül becsüli a kutató népszerűségét!\nHogyan összesítsük az egyes eltéréseket, hogy meg tudjuk határozni a modellünk pontosságát?\n\nPéldául összeadhatjuk őket (sum of errors)\n\nEbben az esetben azt látjuk, hogy az eltérések összege 0\nEz alapján arra következtethetnénk, hogy az átlag tökéletesen reprezentálja az adatokat, azonban az ábrára ránézve láthatjuk, hogy ez nem így van\n\naz egyes értékek és a modell által prediktált értékek között van különbség\n\nMég egy ok az ábrázolás fontossága mellett!\n\n\nA negatív és a pozitív előjelű eltérések kiegyenlítették egymást\n\nEzt elkerülendő négyzetre emelhetjük az eltéréseket az összeadás előtt (sum of squared errors)\n\nÍgy minden eltérés előjele pozitív lesz\nA példánkban a négyzetes eltérések összege 5.20\nMost azonban abba a problémába ütközünk, hogy a modell pontosságának mérője függ a mintánk méretétől\nMinél több megfigyelésünk van, annál nagyobb lesz a modell hiba\n\nEzt elkerülhetjük úgy, hogy összeadás helyett a négyzetes eltérések átlagát vesszük (mean of squared errors)\n\nEhhez elosztjuk a négyzetes eltérések összegét a megfigyelések számával\nÍgy azonban csak a mintánkban lévő átlagos hibát számszerüsítjük\nAzonban célunk, hogy a mintában lévő hibából a populációban található hibát becsüljük meg\nEhhez a minta mérete helyett a szabadságfokkal kell elosztanunk a négyzetes eltérések összegét\nJelen esetben ez n - 1\n\nEzt nevezzük varianciának\n\nÁtlagos négyzetes eltérés az átlagtól\nA varianciával a probléma, hogy a mértékegysége az adatok skálájának négyzete\nA példánkban 1.3\n\nNégyzetes barátok száma nehezen értelmezhető!\n\n\nEzt elkerülhetjük úgy, hogy a variancia gyökét vesszük, ez a szórás\n\nÍgy a modell hibájának mérője ugyanazt a skálát használja, mint a megfigyeléseink\nAz átlaghoz képest kis szórás azt mutatja, hogy a modellunk jól illeszkedik az adatokra\n\nA megfigyelések közel vannak az átlaghoz\n\nPélda\n\nMegkérhetjük a hallgatókat, hogy egy 5-ös skálán értékeljék az egyes statisztika oktatókat\nA mérést elvégezhetjük 5 egymást követő órán\nAz ábrán két oktatónak öt óráján mért összesített értékelései láthatók\nHa az átlagot használjuk, mint statisztikai modellt, mind a két oktatónál ugyanazt az átlagot kapjuk\nMégis látható, hogy az egyik oktatónál a modell jobban illeszkedik az adatokhoz, tehát az átlag pontos reprezentációja az adatoknak\n\nEzt mutatja, hogy a szórás 0.55 az átlaghoz mérten kicsi\nLásd: Figure 3.6 (Field, Miles, and Field (2017))\n\n\n\n\n\n\n\n\n\n\n\nFigure 3.6: Az ábrán két oktató 5 órán keresztül mért teljesítménye látható. Az X tengelyen az órák láthatók, míg az Y tengelyen a teljesítményük. Az első oktatónak a teljesítménye az 5 órán keresztül konzisztensebb volt, mint a második oktatónak. Az átlag teljesítményük azonban azonos.\n\n\n\n\n\n\n3.2.3 Mitől jó egy statisztikai modell?\n\n1) kicsi a hiba\n\nMitől lehet nagy a hiba?\n\nRossz a modell\n\nKimaradt egy fontos prediktor változó\nA prediktor változó hatásának irányát rosszul adtuk meg\n\nPl: azt feltételezi a modell minél idősebb valaki annál alacsonyabb gyerekek körében\n\nAz adatok vizualizációja fontos, hogy jól specifikált modellt tudjunk építeni\n\nMérés hiba/zaj/adatokban lévő variancia miatt\n\nVagy a mérőeszköz nem elég pontos\nVagy egyébb faktorok is befolyásolják a megfigyelt mérésekben lévő varianciát, amikről nem tudunk vagy nem tudjuk mérni\n\n\n\n2) jól generalizálható\n\nha új adatokra illesztjük a modellt, azokat is jól fogja prediktálni\n\nLásd: Figure 3.7 (Poldrack (2018))\n\n\n\n\n\n\nFigure 3.7: Az ábrán 3 különböző modell illeszkedést láthatunk. Az A ábrán jól illeszkedik a lineáris modell az adatokra és az adatokban lévő variancia kicsi. A B ábrán szintén lineáris összefüggést láthatunk, ám a modell hibája nagyobb, mint az A ábrán, az adatokban lévő nagy variancia miatt. A C ábrán egy lineáris modellt illesztettünk az adatokra, ám az adatok nem lineáris összefüggésről árulkodnak. A modell így rosszul illeszkedik."
  },
  {
    "objectID": "descriptive_statistics.html#összesítő-statisztikák",
    "href": "descriptive_statistics.html#összesítő-statisztikák",
    "title": "3  Leíró statisztika",
    "section": "3.3 Összesítő statisztikák",
    "text": "3.3 Összesítő statisztikák\n\nGyakoriság (frequency): a megfigyelések száma (db). Pl. az előadást megnéző hallgatók száma.\nÖsszeg (summary): egy változó összes értékének összeadásával keletkező érték. Pl. covid megbetegedések száma.\nArány (proportion): a megfigyelések száma az összes megfigyeléshez képest (Pl. 54 % vagy 0.54 vagy .54). pl. biciklisek aránya az összes közlekedőhöz képest az Andrássy úton\n\n\n3.3.1 Középértékek\n\nMatematikai átlag (mean, average): Az értékek összege elosztva az értékek számával\n\nÁltalában folytonos változóknál vagy nagy granilaritással rendelkező ordinális változónál használjuk\nAkkor jó használni, ha a változónk eloszlása szimmetrikus\nHa nagy kiugró értékek vannak az átlag torzíthat\n\nAz átlag a négyzetes hibák összegét csökkenti\nA hibák négyzetre emelésénél a kiugró értékeknél exponenciálisan nő a hiba\n\n\nMedián (median): A nagyság szerint sorba rendezett értékek közül a középső. Ha páros számú érték van, akkor általában a középső kettő átlaga\n\nOrdinális változónál használjuk\nAkkor jó használni, ha ferde az eloszlás vagy vannak outlierek\n\nA hibák abszolút értékének összegét csökkenti\nEzért kevésbé érzékeny, nincs négyzetre emelés\nFolytonos változó értékeit rang transzformálhatjuk, ha a kiugró értékek torzítanak\n\nRang transzformáció esetén különböző módszerek vannak arra, hogy milyen értékeket adjunk a sorba álltítás során két megegyező értéknek\n\nPéldául vehetjük a rangsorrend átlagát\nEbben az esetben mind a két hatodik helyre kerülő érték 6.5-ös rang értéket vesz fel\nLásd: Figure 3.8\n\n\n\n\nMódusz (mode): A leggyakrabban előforduló érték\n\nNominális változónál használjuk\n\n\n\n\n\n\n\nFigure 3.8: A felső ábrán a folytonos változó eloeszlása látható rang transzformáció előtt. A kék vonal az átlagot a piros a mediánt jelöli. Az alsó ábrán ugyanaz az eloszlás látható rang transzformáció után. Ebben az esetben az átlag és a medián megegyeznek. Nagy Tamás ábrája.\n\n\n\n\n\n\n3.3.2 Szélsőértékek\n\nMinimum: a legkisebb érték\nMaximum: a legnagyobb érték\nKiugró értékek (outlier): olyan érték, ami a többitől távol esik\n\nAzt, hogy milyen vágási ponttól számít egy érték outliernek sokszor nem könnyen határozható meg.\nFügghet az elmélettől vagy az adott szakterületen használt konvenciók is megszabhatják\nAz outlierek nagy torzító hatással vannak az átlagra\n\nÉrdemes ezért megvizsgálni a változónk eloszlását, mielőtt úgy döntünk, hogy az átlag alapján kívánjuk összesíteni az adatainkat\n\nLehet, hogy torzítani fog = nem jól reprezentálja az adatokat\n\n\nKevésbé torzítják a mediánt\nNem torzítják a móduszt\n\n\n\n\n3.3.3 Helyzetmutatók\n\nKvantilisek: vágási pontok, amelyek mentén a sorba rendezett adatokat meghatározott számú részre bonthatjuk\nKvartilisek: Az adatokat négy egyenlő részre osztó három pont (ld. még decilis, percentilis)\nInterkvartilis tartomány (IQR): A felső (75%) alsó (25%) kvartilis és az alsó kvartilis különbsége, az adatok középső 50%-a \n\nÁltalában ordinális adatok összesítésénél szoktuk használni\n\n\n\n\n\n\nField, Andy, Jeremy Miles, and Zoe Field. 2017. Discovering Statistics Using R. W. Ross MacDonald School Resource Services Library.\n\n\nPoldrack, Russell A. 2018. “Statistical Thinking for the 21st Century.”"
  },
  {
    "objectID": "visualization.html#a-jó-adatvizualizáció-ismérvei",
    "href": "visualization.html#a-jó-adatvizualizáció-ismérvei",
    "title": "4  Adatvizualizáció",
    "section": "4.1 A jó adatvizualizáció ismérvei",
    "text": "4.1 A jó adatvizualizáció ismérvei\n\nAz ábra minden részének legyen információ értéke\n\nFelesleges vagy redundáns elemek ne kerüljenek rá, mert elterelik a figyelmet a lényegről és megzavarják az értelmezést\nOlyan elemek jelenjenek meg csak az ábrán, amelyek nem törölhetők információ veszteség nélkül\nLásd:\n\nadat/tinta arány\n\nFelesleges részek, amik törölhetők információ veszteség nélkül, ne legyenek az ábrán\n\nÁbra szemét\n\nOlyan grafikai elem, ami nem segíti az adatokban lévő információ megértését\n\n\n\nLegjobb megmutatni az egyéni adatpontokat is amennyiben ez lehetséges\n\nAz összesítés torzíthatja az eredményeket\n\nHasználd ki az ábránál a teret, de figyelj rá, hogy közben ne torzítsd az adatokat\n\nKülönböző ábrázolási módok nagyon más történetet tudnak elmesélni\nPélda: szerepeljen-e a nulla érték az y tengelyen vagy ne\n\nFigyelj az emberi percepció limitációira\n\nSzínvakság\n\nHasználj színvak barát színeket\n\nPie chart\n\nAz embereknek ennél a vizualizációs módszernél nagyon nehéz az arányokat helyesen értelmezni!\nNe használjuk!\nFőleg ne felesleges 3. dimenzióval…"
  },
  {
    "objectID": "visualization.html#gyakori-adatvizualizációs-megoldások",
    "href": "visualization.html#gyakori-adatvizualizációs-megoldások",
    "title": "4  Adatvizualizáció",
    "section": "4.2 Gyakori adatvizualizációs megoldások",
    "text": "4.2 Gyakori adatvizualizációs megoldások\n\n4.2.1 Doboz ábra (boxplot)\n\nA helyzetmutatókat általában egy boxplot segítségével vizualizáljuk\nAhol a doboz felső határsa a 75-ik percentilist, az alsó határa a 25-ik percentilist jelöli\n\nA két vonal közötti rész az IQR\n\nA kettő közti vonal a doboz felénél az 50-ik percentilist jelöli\n\nMásnéven medián\n\nA dobozból kijövő függőleges vonalak a 75-ik és a 25-ik percentileseken kívül eső, de még nem outlier értékeket mutatják\n\nEzen kívül pöttyökkel tudjuk jelölni azokat az egyes adatpontokat, amelyek outlier értéknek számítanak\n\nA boxplot néha elfedi a változó eloszlásának formáját\n\nPéldául nem jelzi, ha az eloszlásunk két csúcsú (bimodális)\nEzzel szemben a ferdeség látszik rajta, az egyik kvartilis vizuálisan közelebb van a mediánhoz, mint a másik\nEgy alternatív vizualizációs megoldás a violin plot (hegedű ábra)"
  },
  {
    "objectID": "visualization.html#hogyan-szúrjunk-ki-megtévesztő-vizualalizációs-elemeket",
    "href": "visualization.html#hogyan-szúrjunk-ki-megtévesztő-vizualalizációs-elemeket",
    "title": "4  Adatvizualizáció",
    "section": "4.3 Hogyan szúrjunk ki megtévesztő vizualalizációs elemeket?",
    "text": "4.3 Hogyan szúrjunk ki megtévesztő vizualalizációs elemeket?\n\nSegít-e az ábra megérteni az adatokat, vagy inkább csak összezavar?\nFigyelmesen nézd meg az ábrán a tengelyek nevét és léptékét!\nNézd meg, hogy a tengelyek a nulláról indulnak-e! \nNézd meg, hogy a különböző csoportokat bemutató ábrázolások egyenlő arányban változnak-e egymással\n\nA részek összege nem több mint 100%?\n\nNem hagytak-e ki adatpontot az ábráról?\n\nNincsenek kontextusból kiragadott adatok?\n\nNincsenek olyan vizuális megoldások amik az emberi percepció gyengeségeire építve próbálják az adatokban lévő arányokat torzítani?\n\nPéldául: négyzetes terület nagyságát nehezebben tudjuk megbecsülni, mint egy oszlopét\n\nÖsszevontak-e kategóriákat indokolatlanul?\nSzerepelnek-e olyan adatcsoportok az ábrán, amelyek önkényesen lettek kiválasztva?\nPéldák rossz ábrákra\n\nhttps://venngage.com/blog/misleading-graphs/"
  },
  {
    "objectID": "inferential_statistics.html#mintavételezés",
    "href": "inferential_statistics.html#mintavételezés",
    "title": "5  Következtetéses statisztika",
    "section": "5.1 Mintavételezés",
    "text": "5.1 Mintavételezés\n\nA minta kiválasztásának módja fontos, mert ezzel tudjuk biztosítani, hogy a minta jól reprezentálja a populációnkat\n\nvalószínűségi: minta jól reprezentálja a populációt, ha a populáció minden tagjának egyenlő esélye van a mintánkba való bekerülésre\n\nLegreprezentatívabb\n\nkvóta: a populáció néhány ismert jellemzője alapján válogatunk be meghatározott számú résztvevőt  (pl. 50-50% nő és férfi)\n\nBizonyos jellemzők mentén reprezentatív\n\nkényelmi: az vesz részt a kutatásban, akit éppen elérünk\n\nNem reprezentatív\n\n\nA mintavételezés előnyei és nehézségei\n\nA Figure 5.2 árbrán a minta és populáció paraméterek közti összefüggés látható stilizált formában\n\nA minta és populáció paraméterek közti kapcsolatot jól demonstrálja az alábbi applikáció: https://istats.shinyapps.io/sampdist_cont/\n\nelőnyei\n\nmáshogy nem tudunk információhoz jutni az egész populációra vonatkozóan\ntudunk becsléseket tenni  a populáció jellemzőire (“valódi” átlag, szórás, eloszlás, stb.)\nha ismerjük a hátulütőket, tudjuk kommunikálni a bizonytalanságot is\n\nnehézségei\n\na minta soha nem tökéletes reprezentációja a populációnak, azaz mindig valamennyire torzított\na kisebb minták könnyebben torzítottak, mint a nagyobbak\nnem lehet pontosan tudni, hogy a minta elég jól reprezentálja-e a populációt\nlehet, hogy a minta alapján téves következtetésre jutunk a populációra vonatkozóan\n\n\n\n\n\n\n\n\nFigure 5.2: Az ábrán látható, hogy a populáció paramétert nem tudjuk, de a minták paramétereit igen. Ezek alapján tudunk becslést tenni. Nagy Tamás ábrája.\n\n\n\n\n\n5.1.1 Standard hiba\n\nAttól függetlenül, hogy milyen nagy elővigyázatossággal választottuk ki a mintánkat, a minta különbözni fog a populációtól\n\nEz a mintavételezési hiba (sampling variation)\n\nAbból következik, hogy a populáció összes egyedéből véletlenszerűen választunk ki egyedeket a mintánkba\n\n\nHa többször veszünk mintát egy adott populációból hosszútávon elvárható, hogy a mintáink átlagai leggyakrabban a populáció átlag körül fognak csoportosulni\n\nA minta átlagok eloszlását a mintavételi eloszlásnak (sampling distribution) hívjuk\n\nA mintaátlagok gyakorisági eloszlása\nHa a minta átlagok átlagát vennénk a populáció átlagot kapnánk meg\n\nA minta átlagok populáció átlag körüli szóródását a standard hibával írjuk le\n\nMáshogyan: Azt a bizonytalanságot fejezi ki, amiben a populációátlagtól eltérhet a mintaátlagtól\n\nPontosabb nevén az átlag standard hibája (standard error of the mean).\nKiszámolásához a minta szórását elosztjuk az elemszám négyzetgyökével\nA standard hiba alapján a mérésünk minősége a populációban található variabilitástól és a mintánk méretétől függ\n\nMivel csak a minta méretre van ráhatásunk ennek növelésével javíthatjuk a mérőeszközünk pontosságát\nMinél nagyobb a mintaméret, annál biztosabbak lehetünk abban, hogy a populációátlagot jól közelítjük\n\nAzonban nem csak a minta mérete számít, hanem a mintavételezés módja is\n\nAkármilyen nagy a mintánk, ha annak tagjai nem jól írják le a populációt mert a minta szisztematikusan torzít\nEzért szoktak kutatók általában random mintavételezésre törekedni\n\n\n\nA fent már emltített applikáció jól mutatja, hogyan szóródnak a minta átlagok a populáció paraméter körül: https://istats.shinyapps.io/sampdist_cont/\nÁltalában ezt szokták az ábrákon megjeleníteni hibasávként (error bar)\nHa a hibasávok nem fednek át, akkor arra következtethetünk, hogy a populációban lévő különbség valódi\nA Figure 5.3 ábrán a mintavételi eloszlás és a standard hiba látható Field, Miles, and Field (2017)\n\n\n\n\n\n\n\nFigure 5.3: Az ábrán a populáció és a választott minták kapcsolata látható. Nagy Tamás ábrája.\n\n\n\n\n\n\n5.1.2 Szabadságfok\n\nA minta paramétereket ismerjük (például az átlagot) a populáció paramétereit nem\nA minta paramétereket használjuk fel arra, hogy megbecsüljük a populáció paramétereket\nA szabadságfok (degrees of freedom) azon megfigyelések számát jelöli mintánkban, amit a populáció paraméter becsléséhez felhasználunk\n\nTehát megmutatja, hogy mi az a minimum elemszám, ami a becsléshez kell\n\n\n\n\n5.1.3 Centrális határeloszlás elve\n\nCentral limit theorem (CHE)\nA mintaméret növekedésével a mintaátlagok eloszlása közelít a normális eloszláshoz\nEz akkor is igaz, ha az egyes mintákban lévő eloszlások értéke nem normális!\n\nLásd: Figure 5.4 (Poldrack (2018))\n\nDemonstráció: https://istats.shinyapps.io/sampdist_cont/\nA CHE miatt használhatjuk a legtöbb statisztikai módszert ami normális eloszlást feltételez\n\n\n\n\n\n\nFigure 5.4: A bal oldali ábrán a minta eloszlás látszik, ami eltér a normál eloszlástól. Ezzel szemben a jobb oldalon a mintavételezési eloszlás látható, ami már normál eloszlást követ.\n\n\n\n\n\n\n\n\n\nFigure 5.5: Az ábra X tengelyén a próbák száma, míg Y tengelyen a fej becsült valószínűsége látható. Az ábra jól mutatja, hogy ahogy az elemszám nő a becsült valószínűség is közelebb van a populációben lévő valószínűséghez."
  },
  {
    "objectID": "inferential_statistics.html#konfidencia-intervallum",
    "href": "inferential_statistics.html#konfidencia-intervallum",
    "title": "5  Következtetéses statisztika",
    "section": "5.4 Konfidencia intervallum",
    "text": "5.4 Konfidencia intervallum\n\nAhogy már korábban említettük a minta átlagát használjuk arra, hogy megbecsüljük a populáció átlagot\n\nEzzel az adatokból levont következtetést általánosítsuk (generalization) a mintánkon túlra\n\nLáttuk, hogy különböző mintavételelezések különböző minta átlagokat adnak és a standard hibát használhatjuk arra, hogy meghatározzuk mekkora a mintaátlagok varianciája a populáció átlag körül\nAzt, hogy a minta átlag mennyire jól becsüli meg a populáció értéket úgy is eldönthetjük, hogy kiválasztunk egy értéktartományt, amelybe a populáció átlag feltehetően beleesik\n\nEzt az értéktartományt nevezzük konfidencia intervallumnak\n\nMinél szélesebb a konfidencia intervallumunk annál bizonytalanabbak vagyunk abban, hogy a minta átlag jó reprezentációja-e a populáció átlagnak\n\n\n5.4.1 Helyes értelmezése\n\nA konfidencia intervallumot gyakran félreértik a kutatók\n\nTalán még a p értéknél is gyakrabban!\n\nEgy 95%-os konfidencia intervallum nem azt jelenti, hogy 95% az esélye annak, hogy a populáció átlaga beleesik-e az intervallumba!\n\nA populáció átlag egy fix érték, így egyes esetekben vagy beleesik vagy nem\nNem tudunk valószínűséget rendelni mellé\n\nA helyes értelmezésnél ugyanazt a logikát kell követnünk, mint a hipotézis tesztelésnél: hosszútávon milyen valószínűséggel fogunk helyes döntést hozni\n\nhosszútávon a konfidencia intervallum az esetek 95%-ában fogja tartalmazni a populáció átlagot \nha végtelenszer megismételjük a mintavételt és kiszámoljuk a minta átlagot és a hozzá tartozó konfidencia intervallumot, akkor az esetek 95%-ában a kapott konfidencia intervallumok magukba fogják foglalni a populáció átlagot\nAzt azonban nem tudhatjuk, hogy az éppen általunk gyűjtött mintához kiszámolt konfidencia intervallum tartalmazza-e a populáció átlagot vagy sem\nMásszóval: 95%-os konfidencia intervallum mellett az esetek 5%-ban tévedünk, ha feltételezzük, hogy az adott konfidencia intervallum valóban magába foglalja a populáció átlagot\nA Figure 5.7 ábrán látható, hogy nem minden konfidencia intervallum tartalmazza a populáció átlagot\n\nTermészetesen a valóságban általában nem tudjuk a populáció átlagot, ezért a minta átlag alapján hozunk döntést\n\n\n\n\n\n\n\n\nFigure 5.7: Az ábrán különböző mintákhoz tartozó minta átlagok (a pontok) és a körülöttük lévő 95%-os konfidencia intervallumok láthatók. Az ábra közepén végighúzódó vertikális vonal a populáció átlagot jelöli. Field, Miles, and Field (2017)\n\n\n\n\n\n\n5.4.2 Kiszámítása\n\nA konfidencia intervallumot a z értékek segítségével számoljuk ki\nEgy normál eloszlásnál ahol az átlag 0 és a szórás 1 a z értékek 95%-a a -1.96 és a +1.96-os z értékek közé fog esni\n\nA becslés mögött az a feltételezés áll, hogy a mintavételezési eloszlás hasonlít egy normál eloszlásra\n\nAlsó határa a konfidencia intervallumnak: minta átlag - (1.96 * standard hiba)\nFelső határa a konfidencia intervallumnak: minta átlag + (1.96 * standard hiba)\nA mintánk átlaga mindig a konfidencia intervallum közepe\nA konfidencia intervallum mérete függ a standard hiba méretétől\nHa kicsi a minta a t eloszlást használva kell kiszámítani a konfidencia intervallumot\n\nNagy minta esetén a t-eloszlás megegyezik a normál eloszlással\n\n\n\n\n5.4.3 Vizuális ábrázolása\n\nKonfidencia intervallumok vizuális ábrázolása\n\nÁltalában a konfidencia intervallumot használjuk ábrákon az átlag körüli hiba mértékének vizualizására\nHa két átlaghoz tartozó konfidencia intervallumok átfednek, akkor feltételezhetjük, hogy a két minta átlaga ugyanabból a populációból származik\n\nLásd t-próba\nLásd: Figure 5.8 felső ábráját Field, Miles, and Field (2017)\nMiért fontos, hogy meg tudjuk mondani, hogy két minta nem ugyanabból a populációból származik?\n\nKísérleti kutatási elrendezésnél például az embereket véletlenszerűen két csoportba sorolhatjuk, ahol az egyik csoport valamilyen kísérleti beavatkozáson megy keresztül (péládul egy gyógyszert adunk nekik), amíg a másik csoport nem megy keresztül a beavatkozáson. Ez a kontroll csoport.\nMivel az emberek véletlenszerűen vannak besorolva a két csoportba, így feltételezzük, hogy ugyanabból a populációból származnak\nHa azt találjuk, hogy a két csoport minta átlaga között meglepően nagy különbség van, akkor feltételezzük, hogy a kísérleti beavatkozásunk sikeres volt\n\n\nHa nem fednek át\n\n1) vagy különböző populációból származnak\n2) vagy ugyanabból a populációból származnak de az egyik konfidencia intervallum nem tartalmazza a populáció átlagot\n\nEz az esetek 5%-ában fordul csak elő 95%-os konfidencia intervallum mellett, ezért valószínűleg a 1) opció mellett döntünk\n\nLásd: Figure 5.8 alsó ábráját Field, Miles, and Field (2017)\n\n\n\n\n\n\n\n\nFigure 5.8: Az ábrán két különböző mintavételezésnél kapott minta átlagok és a hozzájuk tartozó 95%-os konfidencia intervallum látható. Field, Miles, and Field (2017)\n\n\n\n\n\n\n\n\nField, Andy, Jeremy Miles, and Zoe Field. 2017. Discovering Statistics Using R. W. Ross MacDonald School Resource Services Library.\n\n\nPoldrack, Russell A. 2018. “Statistical Thinking for the 21st Century.”"
  },
  {
    "objectID": "hypothesis_testing.html#null-hipotézis-szignifikancia-tesztelés",
    "href": "hypothesis_testing.html#null-hipotézis-szignifikancia-tesztelés",
    "title": "6  Null szignifikancia hipotézis tesztelés",
    "section": "6.1 Null hipotézis szignifikancia tesztelés",
    "text": "6.1 Null hipotézis szignifikancia tesztelés\n\nA fejezet során a példa kutatásunkban a statisztika oktatók IQ-ját fogjuk vizsgálni\nElőzetes kutatáskból tudjuk, hogy a populációban az átlago IQ 100 amelyhez egy 15-ös szórás tartozik\n\n\n6.1.1 Lépései\n\nMegfogalmazunk egy alternatív hipotézist\n\nA hipotézisünknek lehet iránya (egyoldalú hipotézis tesztelés)\n\nPozitív vagy negatív kapcsolatot várunk el\nEgy oldalú hipotézis tesztelésnek is nevezik\nPéldául: A statisztika oktatók IQ-ja magasabb, mint 100\n\nVagy lehet kétoldalú hipotézis teszt\n\nEbben az esetben az alternatív hipotézisünk csak azt várja el, hogy a lesz lesz különbség a vizsgált változók között, de az nem mondjuk meg milyen irányú különbséget várunk el\nPéldául: A statisztika oktatók IQ-ja különbözik 100-tól\n\n100 alatti és 100 feletti értékeket is elvárunk\n\n\nAzt, hogy melyik hipotézist alkalmazzuk az elmélet (előzetes tudásunk) határozza meg\n\nMegfogalmazzuk a null hipotézist\n\nEgyoldalú hipotézis esetén a null hipotézis feltételezi, hogy az alternatív által prediktált iránnyal ellenkező előjelű különbséget kapunk vagy nem lesz különbség\nFeltételezzük, hog a null hipotézis igaz!\nPéldául: A statisztika oktatók IQ-ja kisebb vagy egyenlő 100-al\n\nAbban az esetben ez a nullhipotézis, hogyha egy irányú alternatív hipotézisünk van\n\n\nA hipotézis tesztelésére alkalmas adatokat gyűjtünk\n\nPéldául: IQ tesztet töltetünk ki statisztika oktatókkal\n\nTegyük fel, hogy az adatgyűjtés után a mintánkat így írhatjuk le:\n\n30 résztvevő (N = 30)\nIQ átlag (M) = 118.5\nIQ variancia (SD2) = 42.25\nIQ szórás (SD) = 6.5\n\n\nKérdés: Ez a véletlen műve vagy tényleg magasabb a statisztika oktatók IQ-ja, mint az átlagé?\n\nAz alternatív hipotézisünket leíró statisztikai modellt illesztjük az adatokra\n\nCélunk: az alternatív hipotézis mellett szóló evidencia számszerüsítése az adatokban található variancia ellenében\nPélda: Kiszámolhatjuk az átlagot a statisztika oktatók IQ pontszámaira\nA modell illesztése során kiszámoljuk a teszt statisztikát\n\nKiszámoljuk a teszt statisztikát\n\nA teszt statisztikára gondolhatunk úgy, mint a vizsgált hatás mértetének mutatója az adatokban található variancia fényében\n\ntehát teszt statisztika = modell által megmagyarázott variancia / modell által meg nem magyarázott variancia\nmáshogy, teszt statisztika = hatás / hiba\nMinél nagyobb a teszt statisztika annál nagyobb a modell által megmagyarázott variancia a hibához képest\n\nPélda: Amikor a minta átlagot hasonlítjuk a populáció átlaghoz, akkor egymintás t-próbát lehet alkalmazni, aminek teszt statisztikája a t érték\n\nt érték = (Mminta - Mpopuláció) / SD / SQRT(N)\nPélda: t-statisztika: 118-100/1.19 = 15.13\n\n\nMegvizsgáljuk, hogy milyen valószínűséggel kapnánk ilyen vagy ennél extrémebb teszt statisztikát, ha a null hipotézis igaz\n\nEhhez egy valószínűségi eloszlást használunk, ami megmutatja, hogy a null hipotézis alatt, milyen valószínűségeket várnánk el az egyes teszt statisztika értékekhez\nEhhez általában egy elméleti eloszlást használnuk, ami illik a vizsgált teszt statisztikához\n\nPéldául t tesztnél a teszt statisztika a t érték, és t-eloszlást használnuk\n\nAz így kiszámolt valószínűség a p-érték\nA folyamatot ábrázolva a Figure 6.1 ábrán láthatod (Pernet (2015))\nPélda: A t értékünk 15.13 volt és a szabadságfok n-1 = 29, így a p érték kisebb, mint .00001 lesz\n\n\n\n\n\n\n\nFigure 6.1: Az ábra X tengelyén a t értékek láthatók, míg az Y tengelyen a hozzájuk tartozó valószínűség. A piros eloszlás az a valószínűségi eloszlás, amit akkor várnánk el, ha a null hipotézis igaz lenne.\n\n\n\n\n\nÉrtelmezzük az eredmények statisztikai szignifikanciáját\n\nA p-értéket fogjuk használni arra, hogy eldöntsük elég meglepőek-e az adataink ahhoz, hogy elvessük a null hipotézist\nEhhez egy döntési kritériumot kell használnunk, amit a szignifikancia küszöbérték\n\nAz ehhez tartozó valószínáségi görbe alatti terület az alpha\n\nFontos megjegyezni, hogy nem tudhatjuk, hogy a döntés, hogy elvetjük a null hipozétist helyes vagy helytelen döntés-e egy adott esetben!\n\nVagy egyik vagy a másik nem rendelhetünk mellé valószínűséget!\n\nÍgy egyedül azt tudjuk megmondani, hogyha ilyen vagy ennél extrémebb adatokat kaptunk hosszútávon, ha végtelenszer megismételjük a kísérletet és ugyanezt a döntési kritériumot (alphat) használjuk, akkor az esetek hány százalékában fogunk hibásan dönteni\nA Figure 6.1 ábrán egy oldalú teszthez tartozó szignifikancia régiót láthatunk, amit az alpha jelöl, a hozzá tartozó kritkikus érték, azaz a szignifikancia küszöb pedig t = 1.69-nél van\n\nHa kétoldalú hipotézis tesztet csinálnánk az alpha-t elosztanánk kettővel 0.05/2=0.025 és a null hipotézishez tartozó eloszlás mindkét végén jelölnénk\nÍgy a kritikus t értékünk is megváltozna, illetve kettő lenne belőle, egy negatív és egy pozitív\n\nPélda: A kapott p érték kisebb, mint a szignifikancia küszöb így elvetjük a null hipotézist, ami szerint a statisztika oktatók IQ-ja egyenlő vagy kisebb 100-nál\n\n\n\n\n6.1.2 Szignifikancia küszöb\n\nNincs objektíven helyes küszöbérték!\nHagyományosan a szignifikancia küszöb 0.05\n\nAz alpha = 0.05 azt mondja meg, hogyha végtelenszer megismételjük a kutatást hosszútávon 5% az esélye annak, hogy egyes fajú hibát követünk el\nEz azonban csak tradíció kérdése\nPár éve megjelent két cikk is, ami a szignifikancia küszöb újragondolására bíztat\n\nAz egyik amellett érvel, hogy hozzunk érveket amellett, hogy melyik szignifikancia küszöböt választjuk\n\nEz azonban nehéz feladat\n\nA másik amellett érvel, hogy használjunk egy konzervatívabb küszöbértéket alapértelmezettként, ami legyen 0.005\n\nEmögött az a feltételezés áll, hogy a 0.05-ös küszöbérték mellett a nullhipotézissel szembeni evidencia gyenge\n\n\n\n\n\n\n6.1.3 Mit értünk helyes döntés alatt?\n\nNégy lehetséges kimenetel létezik:\n\nElvetjük a nullhipotézist, amikor az valóban hamis\nNem vetjük el a nullhipotézist, amikor valójában igaz\nElvetjük a nullhipotézist, pedig az valójában igaz (egyes fajú hiba)\nNem vetjük el a nullhipotézist, amikor az valójában hamis (kettes fajú hiba)\n\nA kettes fajú hiba előfordulásának gyakoriságát a béta küszöbértékkel tudjuk kontrollálni\n\nÁltalában 0.2 azaz 20%\n\nHa az adataink kellő mértékben valószínűtlenek a null hipotézis fényében, akkor elvetjük azt és az alternatív hipotézist megtartjuk\nHa nem elég valószínűtlenek az adatok, akkor nem tudjuk elvetni a nullhipotézist\n\nEbben az esetben nem tudhatjuk, hogy a populációban valóban nem létezik a hatás vagy csak nem volt elég érzékeny a mérőeszközünk a detektálására!\n\n\n\n\n6.1.4 Többszörös tesztelés\n\nHa többször teszteljük ugyanazokat az adatokat a p érték devalválódik\nNem az egyes tesztekre kell kontrollálni a hibát, hanem a tesztek egész családjára\n\nEzt nevezzük family wise error rate-nek\n\nEzt különböző statisztikai módszerekkel tudjuk kontrollálni\n\nA legalapvetőbb a Bonferroni korrekció ahol elosztjuk az alphát a tesztek számával\n\nRészben ez magyarázza, hogy miért nem lehet az NHST alatt többszörösen tesztelni: azaz megnézni az eredményt újabb adatokat gyűjteni majd megint tesztelni\nHosszutávon a p érték biztosan szignifikáns lesz\n\nMert a nagy elemszám miatt a szórás annyira kicsire csökken, hogy kis különbséget is szignifikánsnak fogunk találni"
  },
  {
    "objectID": "hypothesis_testing.html#hatásnagyságok",
    "href": "hypothesis_testing.html#hatásnagyságok",
    "title": "6  Null szignifikancia hipotézis tesztelés",
    "section": "6.2 Hatásnagyságok",
    "text": "6.2 Hatásnagyságok\n\nA statisztikai szignifikancia nem feltétlenül jelent valós szignifikanciát\n\nPélda: egy szívritmus szabályozó gyógyszer hatékonyságának vizsgálatánál kaphatunk szignifikáns különbséget, amikor összehasonlítjuk azon résztvevők szívritmusát akik kaptak az új gyógyszerből azokéval, akik csak placebót kaptak\n\nettől függetlenül, ha a gyógyszer klinikailag nem értelmezhető módon csökkenti a szívritmus gyakoriságát (mondjuk egy gyógynövényből készült tea hatékonyságával ér fel) a gyógyszercég nem fog pénzt költeni az új gyógyszer piacra dobására\n\n\nA hatásméret (effect size) annak a számszerűsített mutatója, mennyire erős egy összefüggés, vagy mennyire nagy a különbség két csoport között\nVannak nyers hatásméret mutatók\n\nAmik ugyanazt a skálát használják, mint az adatok\nKülönböző skálákon mért hatásméretek így nem összehasonlíthatók\nAzonban a hatás valós szignifikanciájának értelmezése könnyebb velük!\nPélda: A minta átlagunk 118.5 volt, így a nyers hatásmérték 118.5-100=18.5\n\nÉs standardizált hatásméret mutatók\n\nLehetővé teszi az összehasonlítást!\n\nLásd: metaanalízis\n\nKét család:\n\nCsoportok közötti különbségekre\n\nCohen’s d\nPélda: A nyers hatásmértéket elosztjuk a szórással, tehát a standardizált hatásnagysága a statisztika oktatók IQ-ja és az átlag IQ közti különbségnek Cohen’s d = 2.84\n\nVáltozók közötti összefüggésre\n\nKorreláció, odds ratio, risk ratio"
  },
  {
    "objectID": "hypothesis_testing.html#mintaméret-és-annak-becslése",
    "href": "hypothesis_testing.html#mintaméret-és-annak-becslése",
    "title": "6  Null szignifikancia hipotézis tesztelés",
    "section": "6.3 Mintaméret és annak becslése",
    "text": "6.3 Mintaméret és annak becslése\n\nMintaméret: az egymástól független megfigyelések száma\nBefolyásolja a statisztikai erőt: annak valószínűsége, hogy megtaláljuk a hatást, amennyiben az a valóságban is létezik\n\nA kettes fajú hiba inverze\n\nNegatív eredmények esetében fontos a statisztikai erő\n\nKülönben nem tudjuk megmondani hogy valóban nem létezik a hatás vagy csak nem volt elég nagy a mintánk, hogy egy ekkora hatást észleljünk (nem volt elég érzékeny a mérésünk)\n\nA szükséges mintaméret becslést az NHST alatt a priori mintaméret becsléssel végezzük\n\nAz a priori azt jelenti, hogy csak akkor van értelme a mintaméret becslésnek, ha az az adatok gyűjtése és a statisztikai teszt elvégzése előtt történt\n\nEzután vagy megtaláltuk a hatást vagy nem, a kérdés el van döntve\nOlyan a post hoc mintaméret becslés mintha azután próbálnánk meg kiszámolni, hogy mennyi üzemanyag kell egy repülőbe ahhoz, hogy átrepüljünk vele az óceán felett, miután már megtörtént a repülés. A gép vagy lezuhant vagy nem\n\nEhhez kell az elvárt hatásméret, a kívánt statisztikai erő, a szignifikancia küszöb, a kutatási elrendezés\nMinél kisebb az elvárt hatás annál nagyobb mintára lesz szükségünk, hogy észleljük\n\nLásd: Figure 6.2 (Bakker et al. (2016))\n\nAz elvárt hatásméret megbecslésére számos módszer van\n\nHasználhatunk pilot kutatást\nTámaszkodhatunk a szakirodalomban előzetesen talált hatásméretekre\n\nAzonban itt lehetséges, hogy a publikált hatásméretek torzítanak!\n\nElméleti alapon is meghatározhatjuk a számunkra releváns legkisebb hatást\n\nsmallest effect size of interest (SESOI)\nmelyik az a legkisebb hatás, ami számunkra még érdekes lehet\n\n\n\n\n\n\n\n\n\nFigure 6.2: Az ábrán a statisztikai erő, a hatásnagyság és az elemszám közti összefüggés látható. Az X tengelyen az elemszám, az Y tengelyen pedig a statisztikai erő van ábrázolva. A különböző színű vonalak pedig különböző standardizált hatásméreteket jelölnek. Látható, hogy amennyiben kicsi a hatatásméret, akkor sokkal nagyobb elemszámra van szükség azonos statisztikai erő eléréséhez, mint nagy hatásméret esetén."
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "7  Két folytonos változó közti összefüggés",
    "section": "",
    "text": "Statisztikai próbája a korreláció\nTeszt értéke a korrelációs együttható (r)\n\nskálafüggetlen \n-1 és 1 közötti értéket vehet fel a korreláció irányának függvényében\n\nLineáris összefüggést feltételez a két változó között\n\nPozitív: egyik változó nő a másik is nő\nNegatív: egyik változó nő a másik csökken\n\nÖsszefüggés erősségeként lehet értelmezni az r nagyságát\n\nMinél nagyobb annál erősebb az összefüggés\n\n3 típusa van\n\nPearson korreláció:\n\nLegalább intervallum típusú változók\nVáltozók eloszlása normál eloszlást követ\n\nSpearman rang korreláció:\n\nLegalább ordinális típusú változók\n\nKendall tau:\n\nLegalább ordinális\nAlacsonyabb mintaelemszámnál is jó\nJól kezeli ha sok azonos rangú elem van\n\n\nKorreláció null hipotézis tesztje\n\nKritikus értéknél az r-t t-értékké transzformáljuk\nSzabadságfok: n-2\nExcelben nem annyira egyszerű kiszámítani a korrelációs együtthatóhoz tartozó p-értéket, ezért ezen az órán ettől eltekintünk és a korrelációs együttható, mint két folytonos változó közötti kapcsolat erősségét és irányát kifejező mutató értelmezésére koncentrálunk\n\nKorrelációs mátrix\n\nTöbb változó között egyszerre mutatja meg a korrelációs együtthatókat táblázat formájában\n\nKorrelációs együttható négyzete a determinisztikus együttható (R2)\n\nEgyik változó mekkora részt magyaráz a másik változóból\nA variance mekkora részét magyarázza meg\nRegressziónál fontos mutató"
  },
  {
    "objectID": "regression.html#egyszerű-lineáris-regresszió",
    "href": "regression.html#egyszerű-lineáris-regresszió",
    "title": "8  Lineáris regresszió",
    "section": "8.1 Egyszerű lineáris regresszió",
    "text": "8.1 Egyszerű lineáris regresszió\n\nLegsokrétűbb statisztikai próba\nA legtöbb más statisztikai próbát regresszióként is lehet értelmezni\nCélja: a kimeneti változó értékeinek predikciója egy (vagy több) prediktor változó által\nAdat = model + error\n\nLineáris regresszió esetében a modellünk egy egyenes vonal\nA modell a bemeneti változó függvényében ad előrejelzést\nHa ismerjük a prediktor értékét, akkor meg tudjuk mondani mi lesz a kimeneti változó értéke\n\nAzt a lineáris modellt akarjuk megtalálni, ami legjobban illeszkedik az adatokra, ahol legkisebb a hiba\n\n\n8.1.1 Lineáris modell paraméterei\n\nMásnéven regressziós együtthatók (regression coefficients)\nMeredekség (slope): egy egységnyi változás a prediktor változóban (x tengely) mekkora változást okoz a kimeneti változóban (y tengely)\n\nAz egyenes dőlésszöge\nHa pozitív érték, akkor pozitív kapcsolat van a két változó között\n\nHa a prediktor változónk értéke nő a kimeneti változó értéke is nő\n\nHa negatív érték, akkor negatív kapcsolat\n\nHa a prediktor változónk értéke nő, a kimeneti változónk értéke csökken\n\nJele: b1\n\nIntercept: ha a prediktor változó értéke 0, mekkora a kimeneti változó értéke, azaz milyen y értéknél metszi a vonal az y tengelyt\n\nJele: b0\n\nHibatag: a modell által meg nem magyarázott variancia\n\nAz adatoponttól a lineáris regressziós egyenesig húzott szaggatott vonal\n\n\n\n\n8.1.2 Lineáris modell illeszkedésének a vizsgálata\n\nHogyan találjuk meg azt a lineáris modellt, ami legjobban illeszkedik az adatokra?\n\n\n8.1.2.1 A legkisebb négyzetek módszere (method of least squares)\n\nMeghatározásához ugyanazt a módszert használhatjuk, mint amikor az átlag modellnél használtunk\nMegnézzük a modell által prediktált értékek és a valós értékek közötti különbséget: a reziduálisokat (residuals)\nItt is négyzetre emeljük a reziduálisok majd összeadjuk őket (sum of squared differences, SS)\nEzután minden lehetséges vonalra (lineáris regressziós modellre) kiszámíthatnánk őket és ahol az SS a legkisebb az a modell illeszkedik a legjobban az adatokra\nAzonban még a legjobban illeszkedő modell is magyarázhatja rosszul az adatokat!\n\n\n\n8.1.2.2 A null modell\n\nAhhoz, hogy ezt megvizsgálájuk a legegyszerűbb (null) modell illeszkedéséhez hasonlítjuk a regressziós modellunk illeszkedését: az átlaghoz\n\nAz átlag azonban minden adatpontra ugyanazt az értéket fogja prediktálni\n\nPéldául: mennyire számít a marketingre szánt összeg egy film összbevételénél?\n\nHa 1 dollárt költünk a marketingre akkor is ugyanazt a bevétlet prediktálja, mintha 200000$ költüttünk volna rá\n\n\nAz átlag modellnél a hibát összesítve megkapjuk a teljes négyzetösszeget (total sum of squares, SST)\n\nMiért az átlag a legegyszerűbb modell?\n\nBármelyik másik értéket választjuk a legegyszerűbb modellhez, a hibák négyzetösszege (sum of squared residuals) minden esetben nagyobb lesz, mintha az átlag értékét választanánk\n\n\n\n\n\n\n8.1.2.3 Regressziós modell összehasonlítása a null modellel\n\nKiszámítjuk a négyzetre emelt reziduálisok összegét a regressziós modellnél is (residual sum of squares, SSR)\nAhhoz, hogy megtudjuk a regressziós modellünk mennyivel jobban magyarázza az adatokat, mint az átlag modellunk a kettőt kivonjuk egymásból: SST - SSR = SSM (model sum of squares)\n\nÚgy tudunk javítani a modellünkön, ha közelebb kerülnek a modell által prediktált értékek az egyes adatpontokhoz (lásd: Figure 8.1)\n\nÍgy csökken a modell által prediktált értékek és az adatok közti különbség, tehát a reziduálisok nagysága\n\nHa az SSM nagy, a regressziós modell sokkal jobban magyarázza az adatokat, mint az átlag\nA fennmaradó variancia (amit a modell nem tud megmagyarázni) a megmagyarázatlan variancia\n\n\n\n\n\n\n\nFigure 8.1: A bal oldalon lévő ábrán látható statisztikai modell (piros vonal) az átlag. A fekete pontok az egyes adatpontokat ábrázolják. Az átlaghoz tartozó modell négyzetes hibáinak összege 9.05. Ezzel szemben a jobb oldalon a statisztikai modell egy lineáris regressziós egyenes. Ennek a hiba értéke kisebb, 5.43. Tehát a lineáris regressziós modell jobban illeszkedik az adatokra. Nagy Tamás ábrája.\n\n\n\n\n\nMegnézhetjük, hogy arányosan mennyivel javul a modellünk az átlaghoz képest, ha egy prediktor változót is belerakunk\n\nA kettőt elosztva egymással és kivonva egyből megkapjuk a determinisztikus együtthatót R2\n\n1 - SSM / SST\n\nMegmutatja a regressziós modellünk által megmagyarázott variancia arányát a kimeneti változónkban, a teljes varianciához képest (lásd: Figure 8.2)\n0 és 1 közötti értéket vehet fel\nMinél nagyobb az érték a modellünk az adatokban található variancia annál nagyobb százalékát magyarázza meg, tehát annál jobb\nHa megszorozzuk 100-al százalékot kapunk\nA kimeneti változóban lévő varianciának hány százalékát magyarázza meg a modell\nHa ennek a négyzetgyökét vesszük, akkor megkapjuk a Pearson korrelációs együtthatót!\n\n\n\n\n\n\n\nFigure 8.2: A felső a függőleges szaggatott vonalok a regressziós modell által meg nem magyarázott varianciát mutatják. Az alsó ábrán a szaggatott vonalak pedig a teljes varianciát, azaz az átlag és a megfigyelt értékek közötti különbséget. Ha a kettőt elosztjuk egymással és kivonjuk egyből, akkor megkapjuk a determinisztikus együtthatót. Nagy Tamás ábrája.\n\n\n\n\n\nAz F-teszttel is megvizsgálhatjuk a modellünk illeszkedését\n\nF teszt statisztika: szisztematikus variancia / nem szisztematikus variancia\n\nA modell okozta javulás (SSM) / a modell és a megfigyel adatok között lévő különbség (SSR)\n\nMásszóval az F teszt statisztika megmondja, hogy a modell mennyire javítja a becslésünk pontosságát a modellben található pontatlansághoz képest\nItt nem a négyzetes különbségek összegével, hanem átlagával dolgozunk\n\nÍgy nem függ a megfigyelések számától\n\nMean squares for the model (MSS)\n\nSzabadságfok: prediktor változók száma\n\nResiduals mean square (MSR)\n\nSzabadságfok: megfigyelések száma - béta együtthatók száma (meredség + intercept = 2)\n\nJó modellnél 1-nél nagyobb az F arány\np-értéket vagy konfidencia intervallumot is ki tudunk hozzá számolni\n\n\n\n\n\n8.1.3 Prediktor változók szignifikanciájának vizsgálata\n\nNemcsak a teljes modell teljesítményét kell megvizsgálnunk, hanem az egyes paramétereknek a szignifikanciáját is\nA béta megmutatja, hogy a prediktorban való egy egységnyi változás mekkora változást okoz a kimeneti változóban\n\nHa a modell rossz, azt várjuk el, hogy ez nulla legyen\n\nPont, mint az átlagnál!\n\n\nA nullhipotézis a paraméterek esetén az lesz, h a paraméter nem különbözik a nullától\nA kritikus érték pedig a paraméter tényleges értéke\nEzekre gyakorlatilag egy egymintás t-próbát fogunk végezni\n\nt = béta / SE\n\nAz intercept esetén, hogy különbözik-e a nullától az érték.\nA slope esetén, hogy a dőlésszöge különbözik-e a nullától."
  },
  {
    "objectID": "regression.html#lineáris-regresszió-előfeltételei",
    "href": "regression.html#lineáris-regresszió-előfeltételei",
    "title": "8  Lineáris regresszió",
    "section": "8.2 Lineáris regresszió előfeltételei",
    "text": "8.2 Lineáris regresszió előfeltételei\n\nA kimeneti változó folytonos azaz legalább intervallum mérési szintű\nPrediktor típusok: folytonos vagy kategorikus is lehet\nNem zéró variancia: a kimeneti változó és prediktor értékeiben van variabilitás\nA megfigyelések egymástól függetlenek\nA reziduálisok eloszlása normális (a prediktor eloszlásának nem kell normálisnak lennie!)\n\nVizuálisan: \n\nQQ plot\n\nA pontok maradjanak az átló közelében\n\nAz esetek 5%-a lehet 2 szóráson kívül\nAz esetek 1%-a lehet 2.5 szóráson kívül\nAz esetek 0.1%-a lehet 3 szóráson kívül\n\nA Figure 8.3 ábrán egy olyan QQ plot látható, ami azt mutatja, hogy a vizsgált regressziós modell esetében a reziduálisok eloszlása eltér a normálistól\n\nResidual vs fitted values\n\nResiduális értékek vannak az y tengelyen\nModell értékek az x tengelyen\nHa a vonal görbül, nem lineáris kapcsolat\n\n\n\n\n\n\n\n\n\nFigure 8.3: Ha a reziduálisok eloszlása a normális eloszlást követné, akkor az áblán látható adatpontok a szaggatott vonal mentén helyezkednének el. Nagy Tamás ábrája.\n\n\n\n\n\nAz értékek\n\n68%-a egy szóráson belül van\n95%-a két szóráson belül van\n99.7%-a három szóráson belül van\n\nEhhez kapcsolódik, hogy a modellben nincsen sok jelentős kiugró érték (outlier), ami torzítja a modellünket\nAzt várjuk, hogy a lineáris regresszió minden mérési szinten ugyanannyira jó predikciót tudjon adni. Azaz, ugyanolyan hatékony legyen akkor, ha a buszmegállóban 3 ember van, mint akkor, ha 20\nEzt a reziduálisok elemzésével tudjuk ellenőrizni\nEkkor azt mondjuk, hogy a modellünk homoszkedasztikus, azaz a reziduálisok mértéke független a prediktor értékétől.\nEllentéte a heteroszkedaszticitás, ami azt jelenti, hogy pl. a kisebb prediktált értékekhez tartozó reziduálisok kisebbek, mint a nagyobb prediktált értékekhez tartozó reziduálisok\nVizsgálata vizuálisan zajlik\n\nTölcsér alak azt jelenti hogy sérül a heteroszkedaszticitás feltétle (lásd: Figure 8.4)\n\nA kimeneti vagy prediktor változók transzformálása segíthet a reziduálisok homoszkedaszticitásának sérülése során. Ilyen lehet például a természetes logaritmikus transzformáció\n\nIlyenkor figyelnünk kell az eredmények értelmezésére, hiszen a változók transzformálásával az is megváltozik\n\nHa a prediktornak vesszük természetes logarimtusát: 1%-os változás a prediktor változóban a kimeneti változó 0.01*B1 változásához vezet\nHa a prediktornak és a kimeneti változónak is a természetes logaritmusát vesszük: 1%-os változás a prediktor változóban B1%-os változáshoz vezet a kimeneti változóban\n\n\n\n\n\n\n\n\nFigure 8.4: A reziduálisok vizsgálata során az X tengelyen a modell által prediktált értékeket az Y tengelyen a standardizált reziduálisokkal szemben ábrázoljuk. Véletlen szóródást várunk el az adatokban az X tengely összes értékéhez. Az ábrán a tölcsér alakzat heteroszkedaszticitásra utal, tehát a reziduálisok függnek a prediktor értékeitől. Nagy Tamás ábrája.\n\n\n\n\n\nKiugró értékek szűrése\n\nA kiugró értékek “magukhoz húzzák” a regressziós egyenest (lásd: Figure 8.5)\nVizuálisan\n\nTávol esnek a többi értéktől\nMagukhoz húzzák a regressziós egyenest\n\nStatisztikai módszerekkel\n\nCook’s distance\nHa 1-nél nagyobb erős torzító hatása van az adatpontnak\n\nMit tegyünk ha vannak outlierek?\n\nCsak akkor zárjuk ki ha adathibából származnak\nKülönben overfitting veszélye fennáll\n\nNagy elemszánál nem olyan nagy a hatásuk!\n\n\n\n\n\n\n\nFigure 8.5: Az ábrán az outlierek torzító hatása látható a regressziós modellre. A jobb felső sarokban a többi adatponttól távol egy kiugró érték látható, ez húzza magához a pirossal jelölt regressziós modellt. Nagy Tamás ábrája."
  },
  {
    "objectID": "comparing_means.html#a-t-próba-típusai",
    "href": "comparing_means.html#a-t-próba-típusai",
    "title": "9  Két csoport átlagának összehasonlítása",
    "section": "9.1 A t-próba típusai",
    "text": "9.1 A t-próba típusai\n\nEgymintás t-próba\nFüggetlen mintás t-próba\nPáros mintás t-próba\n\nEgy egymintás t-próbaként is lehet értelmezni, ahol a két összefüggő csoport különbségét hasonlítjuk a 0-hoz"
  },
  {
    "objectID": "comparing_means.html#a-t-próba-logikája",
    "href": "comparing_means.html#a-t-próba-logikája",
    "title": "9  Két csoport átlagának összehasonlítása",
    "section": "9.2 A t-próba logikája",
    "text": "9.2 A t-próba logikája\n\nKét mintát veszünk, ahol a mintáink lehetőleg csak az átlalunk vizsgált független változó mentén különböznek szisztematikusan\n\nPl: A) csoport tagjai részt vettek egy képzésen b) csoport tagjai nem vettek rész a képzésen (kontroll csoport)\n\nCélunk, hogy a csoport tagjai lehetőleg minden másban hasonlóak legyenek\n\nNe legyen olyan esetleges torzító faktor (például A) csoportba csak magas IQ-val rendelkező személyek vannak), ami torzíthatja a vizsgált hatást (a képzés hatására jobb pontot érnek-e el a személyek egy teszten)\n\n\n\nA null hipotézis alatt azt várjuk el, hogy a két minta átlagai között nem lesz különbség, a csoportok átlagainak különbsége a függő változóban a nulla körül helyezkedik el\n\nEbben az esetben a két minta feltételezhetően ugyanabból a populációból származik\n\nA megfigyelt minták átlagainak különbségét ahhoz a hipotetikus különbség értékhez hasonlítjuk, amit akkor várnánk el, ha nincs hatás (tehát a null hipotézis igaz)\nA standard hibát használjuk arra, hogy megvizsgáljuk a minta átlagok közti variabilitást\n\nHa a standard hiba kicsi akkor várhatóan a minta átlagok hasonlóak lesznek\nHa a standard hiba nagy akkor várhatóan nagy különbségek is előfordulhatnak a minta átlagok között\nMég akkor is, ha ugyanabból a populációból származnak\n\nHa a megfigyelt minta átlagok közti különbség nagyobb, mint amit elvárnánk a standard hiba alapján, ha a null hipotézis igaz, akkor feltételezhetjük:\n\nA valóságban nincs hatás, a két minta átlag ugyanabból a populációból származik, csak atipikus egyedei annak\n\nMásszóval: távol helyezkednek el a populáció átlagtól\n\nA valóságban van hatás, a null hipotézist elvetjük, a két minta valójában két különböző populációból származik, amelyeknek tipikus tagjai\n\nMásszóval a minta átlagok közel vannak a populációk átlagához, amiből származnak\n\n\nMinél nagyobb a hatás és minél kisebb a standard hiba, annál biztosabbak vagyunk benne, hogy a hatás valóban létezik"
  },
  {
    "objectID": "comparing_means.html#t-próba-mint-stasztikai-modell",
    "href": "comparing_means.html#t-próba-mint-stasztikai-modell",
    "title": "9  Két csoport átlagának összehasonlítása",
    "section": "9.3 t-próba, mint stasztikai modell",
    "text": "9.3 t-próba, mint stasztikai modell\n\nEgy teszt statisztikára gondolhatunk úgy is, mint a variancia, amit megmagyaráz a modellunk elosztva a varianciával, amit nem magyaráz meg a modellünk\n\nhatás / hiba\n\nt-próba esetében a statisztikai modell a két csoport átlagainak a különbsége\nA hiba mutatónk a standard hiba\n\nMegmutatja mennyire fluktuálnak a minta átlagok a mintevételezési hibának következtében\nEzt is az átlagok különbségére számoljuk ki"
  },
  {
    "objectID": "comparing_means.html#t-próba-előfeltételei",
    "href": "comparing_means.html#t-próba-előfeltételei",
    "title": "9  Két csoport átlagának összehasonlítása",
    "section": "9.4 t-próba előfeltételei",
    "text": "9.4 t-próba előfeltételei\n\nA változók legalább intervallum skálájúak\n\nEz az előfeltétele, hogy átlagot tudjunk számolni\n\nA mintavételei eloszlás (sampling distribution) normáls eloszlást követ\n\nA mintavételi eloszlást nem tudjuk közvetlenül megvizsgálni ezért azt nézzük meg, hogy a változók eloszlása normál eloszlást követ-e\n\nA centrális határeloszlás elve miatt feltételezzük\n\nha a változónk eloszlása normális a mintavételi eloszlás is normális lesz\nIlletve sok megfigyelés esetén a mintavételezési eloszlás úgyis a normálishoz közelít\n\n\nPáros t-próba esetén a két csoport értékeinek a különbsége kell normál eloszlást kövessen!\n\nFüggetlen mintás t-próba\n\nAz előfeltételeket tesztelni kell mielőtt a parametrikus Student t-próbát alkalmazhatnánk\nAz előző feltételeken felül:\n\nA különböző csoportokból származó értékek függetlenek egymástól\nSzórás homogenitás: a két csoport szórása hasonló"
  },
  {
    "objectID": "comparing_means.html#t-próba-eredményeinek-ábrázolása",
    "href": "comparing_means.html#t-próba-eredményeinek-ábrázolása",
    "title": "9  Két csoport átlagának összehasonlítása",
    "section": "9.5 t-próba eredményeinek ábrázolása",
    "text": "9.5 t-próba eredményeinek ábrázolása\n\nHegedű ábrával (violin plot)\nBarchart-tal\nNe feledkezzünk meg az error bar-ról!\n\nEz általában a standard hiba (SE)"
  },
  {
    "objectID": "regression.html#többszörös-lineáris-regresszió",
    "href": "regression.html#többszörös-lineáris-regresszió",
    "title": "8  Lineáris regresszió",
    "section": "8.3 Többszörös lineáris regresszió",
    "text": "8.3 Többszörös lineáris regresszió\n\nTovábbi tényezőkről is gondolhatjuk, hogy javítani fognak a modellünkön\n\nEgy bizonyos pont után, ha ezeket a prediktor változókat hozzáadjuk a modellhez, nem fog a hiba szignifikánsan csökkenni\nEz az overfitting\nEredménye: a modell nem lesz generalizálható"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Hivatkozások",
    "section": "",
    "text": "Aczel, Balazs, Bence Palfi, Aba Szollosi, Marton Kovacs, Barnabas\nSzaszi, Peter Szecsi, Mark Zrubka, Quentin F Gronau, Don van den Bergh,\nand Eric-Jan Wagenmakers. 2018. “Quantifying Support for the Null\nHypothesis in Psychology: An Empirical Investigation.”\nAdvances in Methods and Practices in Psychological Science 1\n(3): 357–66.\n\n\nBakker, Marjan, Chris HJ Hartgerink, Jelte M Wicherts, and Han LJ van\nder Maas. 2016. “Researchers’ Intuitions about Power in\nPsychological Research.” Psychological Science 27 (8):\n1069–77.\n\n\nDienes, Zoltan. 2008. Understanding Psychology as a Science:\nAn Introduction to Scientific and Statistical\nInference. Springer.\n\n\nField, Andy, Jeremy Miles, and Zoe Field. 2017. Discovering\nStatistics Using R. W. Ross MacDonald School Resource\nServices Library.\n\n\nFlake, Jessica Kay, and Eiko I Fried. 2020. “Measurement\nSchmeasurement: Questionable Measurement Practices and How to Avoid\nThem.” Advances in Methods and Practices in Psychological\nScience 3 (4): 456–65.\n\n\nFried, Eiko I., and Jessica K. Flake. 2018. “Measurement\nMatters.” APS Observer 31.\n\n\nHardwicke, Tom E., Manuel Bohn, Kyle MacDonald, Emily Hembacher, Michèle\nB. Nuijten, Benjamin N. Peloquin, Benjamin E. DeMayo, Bria Long, Erica\nJ. Yoon, and Michael C. Frank. 2021. “Analytic Reproducibility in\nArticles Receiving Open Data Badges at the Journal\nPsychological Science: An\nObservational Study.” Royal Society Open Science 8 (1):\n201494.\n\n\nKovacs, Marton, Rink Hoekstra, and Balazs Aczel. 2021. “The Role\nof Human Fallibility in Psychological Research: A Survey of Mistakes in\nData Management.” Advances in Methods and Practices in\nPsychological Science 4 (4): 25152459211045930.\n\n\nMichener, William K. 2015. “Ten Simple Rules for Creating a Good\nData Management Plan.” PLoS Computational Biology 11\n(10): e1004525.\n\n\nOlsson-Collentine, Anton, Marcel ALM Van Assen, and Chris HJ Hartgerink.\n2019. “The Prevalence of Marginally Significant Results in\nPsychology over Time.” Psychological Science 30 (4):\n576–86.\n\n\nPernet, Cyril. 2015. “Null Hypothesis Significance Testing: A\nShort Tutorial.” F1000Research 4.\n\n\nPoldrack, Russell A. 2018. “Statistical Thinking for the 21st\nCentury.”\n\n\nReinhart, Carmen M, and Kenneth S Rogoff. 2010. “Growth in a Time\nof Debt.” American Economic Review 100 (2): 573–78.\n\n\nRosnow, Ralph L, and Robert Rosenthal. 1989. “Definition and\nInterpretation of Interaction Effects.” Psychological\nBulletin 105 (1): 143.\n\n\nWicherts, Jelte M., Coosje LS Veldkamp, Hilde EM Augusteijn, Marjan\nBakker, Robbie Van Aert, and Marcel ALM Van Assen. 2016. “Degrees\nof Freedom in Planning, Running, Analyzing, and Reporting Psychological\nStudies: A Checklist to Avoid p-Hacking.”\nFrontiers in Psychology, 1832."
  },
  {
    "objectID": "inferential_statistics.html#valószínűségi-eloszlások",
    "href": "inferential_statistics.html#valószínűségi-eloszlások",
    "title": "5  Következtetéses statisztika",
    "section": "5.2 Valószínűségi eloszlások",
    "text": "5.2 Valószínűségi eloszlások\n\nAhhoz, hogy meghatározzuk milyen valószínűséggel kapunk egy értéket vagy annál nagyobb értéket megnézhetjük egy változó gyakorisági eloszlását\nA (fig_prob_dist?) ábrán például annak a gyakorisági eloszlása látható, hogy hányan ugrottak a tengerbe a tavalyi évben, miután a valószínűségi eloszlásokról kezdtünk magyarázni nekik (Field, Miles, and Field (2017))\n\nHa például arra lennénk kíváncsiak, hogy mekkora eséllyel ugranak a tengerbe 70 éves vagy annál idősebb emberek kiszámolhatnánk ennek a valószínűségét a mintánkban lévő eloszlás alapján\n\nElső ránézésre az adatok alapján azt várnánk el, hogy a jövőben az idősebb emberek ritkábban ugranak a tengerbe, mint mondjuk a 30 évesek\nA konkrét valószínűség kiszámítása viszont minden egyes empirikus eloszláshoz fáradtságos folyamat lenne, szerencsére a statisztikusok kiszámították a valószínűséget (a görbe alatti területet) több nevezetes eloszlás különböző értékeihez\nIlyen a normál eloszlás is, amelynek átlaga 0 és szórása 1 (lásd: ?fig-z_curve)\n\n\nAzonban a mintánkban található eloszlásnak nem 0 az átlaga és a szórása sem 1\nSzerencsére, a standardizálás segítségével a változónk értékeit transzformálhatjuk úgy, a változónk eloszlása a nevezetes normál eloszlásra hasonlítson\n\nEzt z transzformációnak is nevezik, hiszen a transzformáció után standardizált z értékeket kapunk\nA standardizált változó átlaga 0 és mértékegysége a szórás lesz\nA z érték megmondja, hogy az átlagtól hány szórásnyira van egy adott érték\nÍgy az értékek nagyságrendtől és a változások abszolút nagyságrendjétől függetlenül összehasonlíthatók\n\nKülönböző skálán mért változók ábrázolásánál vagy többszörös lineáris regressziónál hasznos eszköz a standardizálás\n\n\nEgy adatpont z értékké való transzformációjához először kivonjuk az értékből az átlagot, majd elosztjuk a szórással\nÍgy már válaszolni tudunk az előző kérdésre, hogy mekkora eséllyel ugranak a tengerbe 70 éves vagy annál idősebb emberek?\n\n70-es nyers értéket z értékké alakítjuk\nTegyük fel, hogy a változó átlaga 36 és szórása 13\nz = (70-36)/13 = 2.62\nEz lesz a kritikus értékünk!\nEzután megnézhetjük, hogy a küszöbértéken túl (hiszen a 70 éves vagy annál idősebb emberek érdekelnek) mekkora a görbe alatti terület a normál eloszlásnál\nEz 0.0044 azaz 0.44%\nAnnak az esélye, hogy valaki, aki 70 éves vagy annál idősebb a tengerbe ugrik, ha a valószínűségi eloszlásokról kezdünk magyarázni neki 0.44%\n\nEz egy viszonylag kis esély, tehát nyugodtan mondjuk fel a Kvantitatív alapok tárgy ezen fejezetét nagyszüleinknek gyakorlás gyanánt!\n\n\n\n\n\n\n\n\nFigure 5.6: Az ábrán annak a gyakorisági eloszlása látható, hogy mennyien ugrottak a tengerbe a tavalyi évben, miután a valószínűségi eloszlásokról beszéltünk velük. Az X tengelyen az életkor látható, az Y tengelyen pedig a gyakoriság. Field, Miles, and Field (2017)"
  },
  {
    "objectID": "inferential_statistics.html#pontbecslés-és-intervallum-becslés",
    "href": "inferential_statistics.html#pontbecslés-és-intervallum-becslés",
    "title": "5  Következtetéses statisztika",
    "section": "5.3 Pontbecslés és intervallum becslés",
    "text": "5.3 Pontbecslés és intervallum becslés\n\nAmikor a mintánk átlaga alapján a populáció átlagot kívánjuk megbecsülni, akkor pontbecslést végzünk\n\nA pontos becslésre viszonylag kicsi az esély\nAz elemszám növekedésével a minta átlag azonban közelebb lesz a populáció átlaghoz\nA becslésben lévő bizonytalanságot a standard hibával tudjuk számszerüsíteni\n\nNagyobb minta elemszám mellett a standard hiba mértéke csökken\n\n\nTudunk intervallum becslést is végezni\n\nEkkor azt becsüljük meg, hogy milyen értéktartományon belül helyezkedhet el a populáció átlag"
  },
  {
    "objectID": "hypothesis_testing.html#a-null-hipotézis-szignifikancia-tesztelés-gyakori-félreértései-és-a-mögöttük-álló-okok",
    "href": "hypothesis_testing.html#a-null-hipotézis-szignifikancia-tesztelés-gyakori-félreértései-és-a-mögöttük-álló-okok",
    "title": "6  Null szignifikancia hipotézis tesztelés",
    "section": "6.4 A null-hipotézis szignifikancia tesztelés gyakori félreértései és a mögöttük álló okok",
    "text": "6.4 A null-hipotézis szignifikancia tesztelés gyakori félreértései és a mögöttük álló okok\n\nAz NHST használatával és értelmezésével kapcsolatban sok a félreértés a gyakorlott kutatók között is\nEz nagyban hozzá tud járulni a tudományos eredmények replikálhatatlanságához és az így kialakult replikációs válsághoz\nA félreértéseknek többek közt statisztika történeti okai is vannak\n\nA módszer kidolgozása Ronald Fisher-hez és Jerzy Neyman-hoz illetve E. S. Pearson-hoz köthető\nFisher nem értett egyet Neyman-Pearson-nal\nA köztük lévő vita időnként igen elmérgesedett\nA most használt NHST módszer a két megközelítés keveréke\n\nValószínűleg egyik megközelítés képviselői sem értenének egyet vele!\n\n\nA következőben pár gyakori félreértelmezését fogjuk megvizsgálni az NHST logikának és feltárjuk a mögöttük álló okokat is\n\n\n6.4.1 Mennyire valószínű, hogy igaz az alternatív hipotézisünk, ha a p-érték kicsi?\n\nOlvashatjuk azt cikkekben, hogy mivel a p-érték a szignifikancia határ alatt volt, ezért valószínű hogy igaz az alternatív hipotézisünk.\nEz azonban helytelen.\nAz NHST nem mond semmit a H0 vagy H1 valószínűségéről, hanem a kapott adatok valoszinusegevel foglalkozik (abbol a feltetelezesbol kiindulva, hogy a H0 igaz).\nKönnyű összekeverni annak a valószínűségét hogy mennyire valoszínűek a kapott adatok a hipotézis fényében P(D|H) azzal hogy mennyire valószínű a hipotézis a kapott adatok fényében P(H|P)\nEgy hipotézis vagy igaz vagy hamis\n\nNem lehet egy obejktív valószínűséget rendelni egy hipotézishez az NHST alatt\n\nFontos tudni, hogy nem felcserélhetők az állítások! Egy kondicionális valószínűség P(A|B) inverze nem feltetlenül egyenlő a kondicionális valosínűséggel P(B|A)\n\nPélda:\n\nHa leharapta egy ember fejet egy cápa mennyire valószínű, hogy halott? 1\nHa valaki halott, akkor mennyire valószínű hogy leharapta a fejét egy cápa? Nem tudjuk, ~0\n\nEhhez el kell osztani az összes meghalt ember számát azokéval akik azért haltak meg mert leharapta a fejük egy cápa\n\nDienes (2008)\n\n\nTanulság: mit mondhatunk el akkor ha a p értékünk kicsi? Annyit, hogy ha a null hipotézist igaznak vesszük akkor meglepő ilyen adatot kapni\n\n\n\n6.4.2 Ha a kutatásomban kiszámolt teszt statisztikához tartozó p érték nagyon kicsi akkor a talált hatás nagyobb, mintha nagyon nagy lenne a p-érték?\n\nNem\nA p érték hatásméret mutatóként való értelmezése gyakori a publikált irodalomban és Fisher korai írásainak téves értelmezésének következménye\nA p érték nagysága függ többek között a mintaméret nagyságától és a mérőeszköz pontosságától. Így ha a mintaméret nagy és/vagy a mérőeszköz pontos, akkor kis hatásméret mellett is kaphatunk kis p értéket és fordítva.\nRészben ebből következik, hogy a p-érték nagyságából nem következtethetünk a talált hatás fontosságára sem.\n\nPélda: Ha a vérnyomáscsökkentő klinikailag elhanyagolható mértékben csökkenti a vérnyomást, de a szignifikancia küszöböt átlépi a p értékünk, attol még nem fog egy gyógyszercég milliárdokat költeni a gyógyszer piacra dobására\n\n\n\n\n6.4.3 Ha kicsi p ertek miatt elvetem a nullhipotézist, akkor mennyire lehetek biztos abban (mekkora az evidencia) hogy az alternatív hipotézis igaz?\n\nNem következtethetünk a p-értékből az evidencia méretére\nAhogy korábban is már említettük a p-érték nem a hipotézisre vonatkozik\nEzen felül egy igen kicsi p-értéket nem értelmezhetjük úgy hogy több evidenciánk van arra, hogy igaz az alternativ hipotézis\n\nEz a szakirodalomban sokszor úgy jelenik meg hogy: szignifikánsabb eredményt találtunk vagy a kapott eredmény nagyon szignifikáns\n\nAmennyiben a valóságban a nullhipotézis az igaz, a p-értékek eloszlása uniform eloszlást követ (x tengellyel párhuzamos az eloszlás)\n\nTehát ugyanannyi nagyon kicsi p-értéket fogunk kapni mint nagyon nagyot hosszú távon\nÍgy egyetlen kutatásból kapott p-érték nagysaga alapjan semmit nem tudunk elmondani arrol, hogy mennyire valoszinu az adott hipotezis\n\nAmennyiben a valosagban az alternativ hipotezis az igaz, a p ertekek eloszlasa a szignifikancia kuszob korul fog csucsosodni de nagy p ertekek tovabbra is elofordulhatnak\nReszben ez az eszrevetel inspiralta a p-curve hasznalatat\n\nA p curve azt mutatja meg hogy egy adott hatas vizsgalata soran milyen eloszlast kovetnek a kapott p ertekek\nA p curve hasznalata a gyakorlatban azonban sokszor ugyancsak felrevezeto lehet\nEgyik feltetele ugyanis, hogy a kutatok az osszes meres eredmenyet lekozlik, fuggetlenul attol, hogy szignifikans volt-e az eredmeny vagy nem\nAzonban az NHST rituale hasznalatanak egyik kovetkezmenye a fiok hatas\n\nA fiok hatas azt jelenti hogy a kutatok szelektiven kozlik kutatasi eredmenyeik, hajlamosabbak a szignifikans eredmenyeket lekozolni, a nem szignifikans eredmenyek azonban a fiokban maradnak\nFontos azonban megjegyezni hogy az NHST ritualevel kapcsolatos felreertesek nem csak a kutatok koreben elterjedtek, hanem a tudomanyos folyoiratok szerkesztoi koreben is\n\nÍgy egyes lapok hajlamosabbak nem leközölni a nem szignifikáns eredmenyeket\n\n\n\n\n\n\n6.4.4 Ha a p-értékünk éppen a szignifikancia küszöb felett van (p = 0.06) akkor mondhatjuk, hogy marginálisan szignifikáns eredményeket kaptunk?\n\nSzintén a p-érték evidencia mutatóként való értelmezése vezet a következő gyakran elkövetett téves értelmezéshez: marginálisan szignifikáns p-érték\nA kutatók legtöbbször az arbitrális 0.05 szignifikancia küszöböt (alpha) hasznaljak\nA szignifikancia küszöbhöz közeli nem szignifikáns p-értékeket sokszor marginálisan szignifikáns értékeknek nevezik, vagy szignifikáns tendenciáról beszélnek\nRosnow and Rosenthal (1989) híres mondása: \"Surely God loves the .06 nearly as much as the .05\" (p. 1277)\nAz, hogy az alpha értékhez közelítő p-érték annak a jele, hogy a hatás igaz lehet, csak akkor áll fent, ha a hatás jelen van a populációban, míg ha nincs jelen, a p-értékek uniform eloszláslást követnek. Így körkörös érvelésbe kerülünk: a választ, magával a válasszal indokoljuk. \nÚjfent, a p-érték alapján az NHST keretben egy dichotóm döntést hozunk, egyetlen szerepe, hogy általa lássuk, hogy az általunk meghatározott hibahatáron belül vagy kívül esnek az adataink.\n1985 és 2016 között 7 pszichológiai tudományos területen vizsgálta Olsson-Collentine, Van Assen, and Hartgerink (2019) a 0.05 és 0.1 közötti publikált p-értékeket, ezek közül csaknem 40 %-ot marginálisan szignifikánsként közöltek\nA kutatók sokszor evidenciaként tekintenek a p-értékre.\nAz is motiválhatja a kutatókat arra, hogy ilyen p-értékek esetén, próbáljanak értelmezésükben \"közeledni\" a szignifikáns p-értékhez, hogy az NHST keretben nemszignifikáns p-érték esetén nem lehet levonni semmilyen következtetést, így kutatásuk inkonkluzív marad.\n\n\n\n6.4.5 Ha nagy a p értékem akkor igaz, hogy nem létezik a hatás?\n\nMostanra talán már látható, hogy miért nem a válasz a kérdésre\nEgyik kutatásunkban azt vizsgáltuk hogyan értelmezik a kutatók a nem szignifikáns eredményeiket vezető pszichológiai lapokban es az esetek mekkora részében jelent ez tenyleg evidenciát a nullhipotézis mellett Aczel et al. (2018)\nTöbbféle téves értelmezést találtunk az esetek 72%-ában\n\nAbban is volt különbség, hogy a mintára (⅔) (\"Nem volt különbség a résztvevők között a intervenciós és a kontroll csoportban\") vagy a populációra (⅓) (\"Nem volt hatása az intervenciónak\") fogalmazták meg az állítást, hogy nincs jelen a hatás az eredményük alapján\n\nHa nem szignifikáns eredményt kapunk, akkor nem tudhatjuk, hogy csak nem volt elég érzékeny a mérőeszközünk, vagy valóban nem létezik a hatás. Így csak annyit mondhatunk, hogy nem utasíthatjuk el a null hipotézist.\nAhogy mar tobbszor emlitettuk a frekventista statisztikai megkozelitessel nem tudjuk meghatarozni, hogy mennyi evidenciank van egy adott hipotezis mellett\nEhhez egy masik statisztikai megkozelitest a Bayesianus megkozelitest alkalmaztuk\nEzen iskolan belul az egyik gyakran hasznalt mutato a bayes factor ami megmutatja, hogy mennyire valoszinu a nullhipotezis az alternativ hipotezissel szemben\nA bayes faktort relativ evidenciakent tudjuk ertelmezni\nEz azt jelenti, hogy egy kettes BF azt jelenti, hogy a ketszer valoszinubb az alternativ hipotezis, mint a null hipotezis\nBar relativ evidenciakent ertelmezehto a bf megis a kutatok szeretnek dontest hozni, ezert konvenciokat alakitottak ki, hogy hanyas bayes faktor jelent eleg jo evidenciat az egyik vagy a masik hipotezis mellett\n\nA peldaban a harmas bf-t lathatjuk, mint hatart\n\nA bf masik jo tulajdonsaga, hogy meg tudja mondani azt is ha az adatok fenyeben nincs eleg bizonyitekunk arra, hogy a null vagy az alternativ hipotezis mellett dontsunk, ilyenkor az eredmenyek inkonkluzivak\n\nTovabbi adatokat gyűjthetnek\nAz NHST logika szerint nem szignifikans eredmenynel nem tudjuk megmondani, hogy valoban nem letezik a hatas vagy csak nem eleg erzekeny a meroeszkozunk vagy nem eleg adatot gyujtottunk\n\nTovabba az ujboli teszteles ujabb adatok gyujtese utan torzitja az NHST alatt az eredmenyeink\n\nIlyenkor az alpha szintet korrigalnunk kell\n\n\n\nA teszt statisztikak es a hozzajuk tartozo szabadsagi fokok alapjan ki tudtuk szamolni a bf-et a nemszignifikans hatasokhoz\n\nAzt talaltuk hogy sok esetben amikor a kutato azt mondta a p ertek alapjan, hogy nincs hatas valojaban az eredmenyei inkonkluzivak voltak\nEgyes esetekben pedig az alternativ hipotezist tamogattak\n\n\n\n\n\n\nAczel, Balazs, Bence Palfi, Aba Szollosi, Marton Kovacs, Barnabas Szaszi, Peter Szecsi, Mark Zrubka, Quentin F Gronau, Don van den Bergh, and Eric-Jan Wagenmakers. 2018. “Quantifying Support for the Null Hypothesis in Psychology: An Empirical Investigation.” Advances in Methods and Practices in Psychological Science 1 (3): 357–66.\n\n\nBakker, Marjan, Chris HJ Hartgerink, Jelte M Wicherts, and Han LJ van der Maas. 2016. “Researchers’ Intuitions about Power in Psychological Research.” Psychological Science 27 (8): 1069–77.\n\n\nDienes, Zoltan. 2008. Understanding Psychology as a Science: An Introduction to Scientific and Statistical Inference. Springer.\n\n\nOlsson-Collentine, Anton, Marcel ALM Van Assen, and Chris HJ Hartgerink. 2019. “The Prevalence of Marginally Significant Results in Psychology over Time.” Psychological Science 30 (4): 576–86.\n\n\nPernet, Cyril. 2015. “Null Hypothesis Significance Testing: A Short Tutorial.” F1000Research 4.\n\n\nRosnow, Ralph L, and Robert Rosenthal. 1989. “Definition and Interpretation of Interaction Effects.” Psychological Bulletin 105 (1): 143."
  }
]
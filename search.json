[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kvantitatív Alapok",
    "section": "",
    "text": "Előszó\nEz a könyv a Neumann János Egyetem és az MNB Intézet által indított Nemzetközi Gazdaság és Gazdálkodás mesterszakának Kvantitatív alapok nevű tantárgyához készült. Célom a hallgatók felkészülését segíteni azzal, hogy egy helyen, átlátható formában közlöm a tantárgyhoz készült jegyzeteket, példákat, gyakorlatokat és ábrákat. A Kvantitatív alapok tantárgy felépítésénél akárcsak ezen könyv megírásánál nagyban merítettem Russ Poldrack Statistical Thinking for the 21st Century című munkájából, Nagy Tamás Adatelemzés és statisztikai következtetés nevű órai jegyzeteiből és Andy Field statisztika tankönyveiből. Ha az olvasó ezen művekből ismerős gondolatokat, példákat vagy magyarázatokat lát, akkor azok nagy valószínűséggel onnan is lettek átvéve. Én magam is nagyrészt tőlük tanultam azt, amit a kvantitatív elemzésről tudok. Ez a három ember nálam sokkal többet gondolkozott azon, hogyan kell hatékony módon statisztikát tanítani egyetemista hallgatóknak, így nem láttam értelmét, hogy a tantárgy felépítését a nulláról kezdjem. Ezúton is szeretném megköszönni a segítségük!\n\n\nKöszönetnyílvánítás\nSzeretnék továbbá köszönetet mondani Ignits Györgyinek, Kapitány Balázsnak, Szászi Barnabásnak és Szécsi Péternek, akik példa adatok megosztásán keresztül segítették a könyv létrejöttét.\nA KÖNYVÖN MOST IS AKTÍVAN DOLGOZOM, EZ NEM A VÉGLEGES VÁLTOZAT!"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Bevezetés",
    "section": "",
    "text": "A kvantitatív elemzés nem az adatoknál kezdődik. Az eddigi oktatói tapasztalataim alapján amikor egy hallgató elakad egy önálló elemzési feladat során az nem azért van mert helytelenül magolta be az éppen alkalmazott statisztikai teszt előfeltételeit, vagy mert nem tudja a standard hiba képletét. Ezekre a kérdésekre egy gyors Google kereséssel könnyen meg lehet találni a választ.\n\nHanem mert nem látja át az empirikus tudományos módszer egészét, annak lépéseit és összefüggéseit\n\nNincs jól megfogalmazott hipotézis\nNem feltett kutatási kérdés megválaszolásához szükséges mérőeszközöket használtak\nNem látják át a rosszul strukturált adattáblát\nNem értik a frekventista hipotézis tesztelés működését\nÉs csak ezután jön, hogy nem értik milyen statisztikai eljárást kell alkalmazni és azt hogyan\nEzzel a lépéssel kapcsolatban én is gyakran teszek fel kérdéseket kollégáknak és az internetnek (és bíztatok mindenkit, hogy tegyen ugyanígy)"
  },
  {
    "objectID": "scientific_method.html#a-tudomány-célja",
    "href": "scientific_method.html#a-tudomány-célja",
    "title": "2  Tudományos módszer",
    "section": "2.1 A tudomány célja",
    "text": "2.1 A tudomány célja\n\nA tudomány célja, hogy általános magyarázotokkal szolgáljon a minket körülvevő világról\nA tudományos magyarázatok leegyszerüsített formában írják le a valóságot\nA tudományos magyarázatok segítségével így képesek vagyunk\n\njól informált döntéseket hozni\npredikciókat alkotni új helyzetekre a már meglévő tudásunk alapján\n\nKésőbb majd látni fogjuk, hogy a kutatási folyamat sok pontján félrecsúszhat az, hogy a kutatásunk alapján megbízható döntéseket hozzunk vagy predikciókat alkossunk\nA tudományos megközelítés azonban nem az egyetlen mód, amelyen keresztül a valóságot magyarázzuk\nMiben más, mint egyéb megismerési módok?\n\nPl: vallás: autoritás alapú\nKritikai megközelítés\nTesztelhető (falszifikálható hipotézisek"
  },
  {
    "objectID": "scientific_method.html#az-empirikus-tudományos-folyamat-lépései",
    "href": "scientific_method.html#az-empirikus-tudományos-folyamat-lépései",
    "title": "2  Tudományos módszer",
    "section": "2.2 Az empirikus tudományos folyamat lépései",
    "text": "2.2 Az empirikus tudományos folyamat lépései\n\nÁltalános kérdésfelvetés\n\nEz talán a legegyszerűbb lépés, az ember kíváncsi természetű, szeretné érteni az őt körülvevő valóságot\n\nElmélet alkotás\n\nAhhoz, hogy egy kérdést meg tudjunk válaszolni empirikus módon egy elméletet kell alkotnunk a kérdés mögött álló lehetséges hatásmechanizmusról\nAz elmélet falszifikálható kell legyen\n\nTudunk olyan megfigyeléseket tenni amelyek fényében az elméletet elvetjük\n\nA jó elméletek\n\nElérés (reach): minél több jelenséget magyaráz meg egy elmélet annál jobb\nParszimónia: két versenyző elmélet közül az a jobb, ami kevesebb elemből áll\n\nLásd Occam borotvája\n\nKonzervatívizmus: Mennyire illeszkedik már meglévő tesztelt és elfogadott elméletekhez\n\n\nHipotézis alkotás\n\nA hipotézis az elméletünknek egy konkrétan tesztelhető operacionalizált része\nEgy elmélet alapján többféle hipotézist fel lehet állítani\nA hipotézis alapján predikciókat alkotunk, amelyeket tesztelünk\nEgy hipotézis bizonyításával nem bizonyítjuk az elméletet is!\nDe tudjuk a teszt eredményei által tovább finomítani az elméletet\nVagy elvetjük azt\nFontos, hogy a hipotézis valóban illeszkedjen az adott elmélethez\n\nKutatási elrendezés\n\nA hipotézis tesztelésére annak feltételezései alapján egy kutatást tervezünk\nA kutatás megtervezésénél számos különböző módszertan közül tudunk választani\nMindegyiknek vannak előnyei és hátránya, a hipotézis és az elérhető erőforrások fényében választunk közülük\n\nKérdőíves\nMegfigyeléses\nKísérleti\n\nVan pár általános szempont, amelyeket módszertantól függetlenül figyelembe kell vennünk és amelyek befolyásolják az eredményekből levontható következtetéseket\n\nMinta felépítése és mintaméret\nMérőeszköz és annak pontossága, megbízhatósága, és granularitása\n\nAhhoz hogy oksági viszonyt feltételezzünk két jelenség közt nem feletkezhetünk meg az adatgyűjtés módjáról\nMegfigyeléses vizsgálatoknál nem tudjuk biztosan kijelenteni hogy két változó között oksági viszony van\n\nLehetséges hogy egyébb faktorok befolyásolják a kapott együttjárást\nhttps://www.tylervigen.com/spurious-correlations\n\nEzért a kutatók általában az oksági viszony meghatározásához kísérleti kutatási elrendezést használnak (pl: randomized control trial)\n\nA lehetséges, de nem viszgált befolyásoló faktorokat random mintavételezés útján zárják ki az adatgyűjtés során\n\nVannak statisztikai módszerek amivel utólag is kontrollálni tudjuk ezeket a változókat, de sokkal nehezebb ezt utólag megtenni\nEz is kiemeli a jól megtervezett kutatások és részletesen kidolgozott elméletek fontosságát!\nMintavételezés\n\nAz esetek kis részében tudjuk az egész populációt vizsgálni\nMinták tesztelésén keresztül vonunk le általános következtetéseket\nDe mekkora mintára van szükség ahhoz, hogy a populációra tudjunk következtetni?\n\n\nAdatok feldolgozása\n\nÁltalában nem szokták külön lépésként kezelni, de az óra témaja és az eredményekre gyakorolt lehetséges hatása miatt fontos megemlíteni\nA kapott adatokat befolyásolja az általunk választott kutatási elrendezés és az adatgyűjtés során fellépő váratlan torzító tényezők\nNagyon ritka esetben készek az adatgyűjtés után az adatok az elemzésre\nÁltalában először adat rendezést és adattisztítást kell elvégeznünk\n\nStatisztikai elemzés\n\nAz elemzés során használhatunk\n\nLeíró statisztikai eljárásokat\nKövetkeztetéses statisztikai eljárásokat\n\nRengeteg statisztikai eljárás van, a statisztikusok most is dolgoznak újak kifejlesztésén és validációján\nAz, hogy milyen eljárást választunk függ a hipotézisünktől, a kutatási elrendezésünktől, és az adatgyűjtés során kapott adatoktól\nTöbbféle lehetséges valid elemzési út is létezik\n\nLást: multi-analyst study\n\n\nEredmények értelmezése\n\nA statisztikai elemzés eredményeinek értelmezésére a tudományos folyamat összes eddigi lépése kihat\nKutatóként szeretnénk egyértelmű válaszokat kapni az általunk feltett kérdésekre\n\nSajnos nagyon kevés esetben ez a helyzet\nEz részben a tudományos folyamat összetettségének az eredménye\nRészben ennek a vágynak is szerepe van a p-értékek abuzálásában\nEgy kutatásból nagyon ritkán kapunk egyértelmű válaszokat\n\nLásd: metaanalízis, szisztematikus összefoglaló (systematic review)\n\n\nPár példa helyzet arra, amikor a tudományos módszer összetettsége árnyalja a statisztikai elemzés eredményeinek értelmezését:\n\nA választott mérőeszközök valójában nem a vizsgált konstruktumot mérik\nA minta milyensége vagy mérete nem indokolja az eredmények általánosítását\nAz adattisztítás során olyan megfigyelések is bent maradtak, amelyek szisztematikusan torzítják az eredményeket\n\nAz értelmezést korlázotó tényezőkről általában a tudományos publikáció limitációk szakaszában számolunk be"
  },
  {
    "objectID": "scientific_method.html#a-statisztika-szerepe-a-tudományban",
    "href": "scientific_method.html#a-statisztika-szerepe-a-tudományban",
    "title": "2  Tudományos módszer",
    "section": "2.3 A statisztika szerepe a tudományban",
    "text": "2.3 A statisztika szerepe a tudományban\n\nA komplex valóság egyszerüsített leírása, ami egyúttal azt is elmondja mennyire lehetünk bizonytalanok ebben a tudásban\nMiért van szükség a statisztikára?\n\nHeurisztikák veszélye\n\nPélda: USA bűnelkövetések gyakorisága\n\nSokkal gyakoribbnak gondoljuk a bűnelkövetések számát, mint amilyen gyakoriak a valóságban\nElérhetőségi torzítás (kognitív torzítás egyik fajtája)\nMédia szerepe?\n\n\nStatisztika segít abban hogy tanuljunk az adatokból\n\nHogyan frissítsük előzetes tudásunk az új adatok fényében\n\n\nA statisztika az adatösszesítésről szól\n\nHogyan tudunk úgy leegyszerüsíteni befogadhatatlan mennyiségű megfigyelést, hogy azok segítségével hipotézisünk tesztelni tudjuk, de fontos információ ne vesszen el\n\nA statisztika a bizonytalanság kezeléséről szól\n\nA világ összetett\nA legtöbb összetett jelenséget nehéz determinisztikus módon megmagyarázni\nBár tudunk ok-okozati kapcsolatot felállítani bizonyos összefüggések között általában ezek nem determinisztikus, hanem probabilisztikus predikciókhoz vezetnek\n\nLásd: dohányzás és tüdőrák\n\nTudjuk, hogy a dohányzás növeli a tüdőrák esélyét, azonban nem lehet biztosra mondani, hogyha valaki dohányzik, akkor mindenképp tüdőrákos is lesz\n\n\nA statisztika nem tud bizonyítani (úgy ahogy a matematika tud)\n\nHanem evidenciát tud felmutatni egy hipotézis mellett az eddigi megfigyelések fényében, de a bizonytalanságot nem tudjuk nullára csökkenteni\n\n\n\nA statisztika a kompromisszomkról szól\n\nNincs egyetlen objektív módszer a statisztikában\nMindig a vizsgált kérdés, az adatgyűjtést és elemzést korlátozó tényezők függvényében kell megtalálnunk a legmeggyőzőbb elemzési utat\n\nAhhoz, hogy a választott elemzési út ténylegesen meggyőző legyen transzparensen közölnünk kell analitikus döntéséinket és a mellette szóló érveket\nEz az alapfeltétele az analitikus megismételhetőségnek: más kutató ugyanazokat az adatokat vizsgálva megegyező analatikus úton ugyanarra az eredményre érkezik\n\nEz sajnos ma a tudományban nem magától értetődő!\n\n\nTöbb valid elemzési út is lehet ugyanannak a kérdésnek a vizsgálatára\n\nA szakmai közösség feladata ezeknek a felülbírálata\nLásd: multi analyst kutatások\n\nA tudomány iteratív módon lépésenként épül fel\n\nLehetséges, hogy a ma még megbízhatónak számító elemzési utat új eredmények fényében elvetjük\nÉs ezzel nincs baj!"
  },
  {
    "objectID": "data.html#mi-az-adat",
    "href": "data.html#mi-az-adat",
    "title": "3  Adat",
    "section": "3.1 Mi az adat?",
    "text": "3.1 Mi az adat?\n\nAz adat változók összessége, amelyek valamilyen mérés eredményét rögzítik\n\nAz adat, angolul data többesszám, egyesszámban datum\n\nTehát data are és nem data is!\n\n\nSokszor gondolunk az adatra, mint egy adott, önmagában létező dologra. Ezzel szemben, az adat egy dolog mérés által létrejött reprezentációja\n\nTehát a mérés módja befolyásolja az adatok jelentését és minőségét\nIlletve a mérés befolyásolja az adatokból levont következtetéseket is\nIsmerhetünk akárhány statisztikai trükköt az adatok tisztítására, transzformálására, összesítésére, ha azok zajos, torzított, hibás mérésből származnak az adatokból statisztika útján levont következtetések is torzítani fognak\nEzért fontos már a kutatás megtervezésekor nagyon odafigyelni mit mérünk és milyen pontosságal tudjuk mérni.\nAz adatok létrejöttével a kutatásmódszertan foglalkozik\nPélda:\n\n1999-ben a Mars Climate Orbiter a Mars atmoszférájába lépve darabokra hullott, mert az egyik modulja angolszász mértékegységeket használt, míg a másik metrikusat\n\nTovábbi olvasmányok:\n\nhttps://www.psychologicalscience.org/observer/measurement-matters\nhttps://journals.sagepub.com/doi/full/10.1177/2515245920952393\n\n\nMinden változónak legalább két különböző értéke kell legyen, hogy változónak nevezzük, különben egy konstans lenne\nA változóknak különböző típusai lehetnek, annak fényében milyen mérés eredményeit rögzítik"
  },
  {
    "objectID": "data.html#hogyan-keletkeznek-az-adatok",
    "href": "data.html#hogyan-keletkeznek-az-adatok",
    "title": "3  Adat",
    "section": "3.2 Hogyan keletkeznek az adatok?",
    "text": "3.2 Hogyan keletkeznek az adatok?\n\n3.2.1 Mit mérünk?\n\nElméleti konstruktumok vagy valós fizikai tulajdonságok\n\nSok esetben, főleg a viselkedéses közgazdaságtanban nem fizikai tulajdonságokat mérünk, hanem közvetlenül meg nem figyelhető élméleti konstruktumokat\n\nPl: boldogság\n\n\nAz elméleti konstruktumok mérésénél fontos, hogy hogyan operacionalizáljuk azok mérését\n\nBoldogság: mosolyok száma egy nap alatt vagy önbevallásos kérdőív 1-től 7-ig terjedő skáláján adott pontok\n\nValiditás (érvényesség)\n\nAzt mutatja meg, hogy mennyire mérjük azt, amit valójában mérni akarunk\nTöbbféle validitás mutató is van\n\nLátszatérvényesség\n\nElső ránézésre úgy tűnik-e, hogy a mérőeszközünk azt méri, amit mérni akarunk\nPl: vérnyomást a nyelv pirossága mentén szeretném megmérni valószínűleg a mérőeszközöm nem érvény adatokat fog adni\n\nKonstruktum validitás\n\nKét része van:\n\nKonvergens validitás\n\nA mérőeszköz mérései pozitív együttjárást mutatnak ugyanazt a konstruktumot vizsgáló más mérőeszközök méréseivel\n\nPl: boldogságot vizsgálom kérdőíves és interjú módszerrel is, az eredmények között pozitív kapcsolatot várok el\n\n\nDivergens validitás\n\nA mérőeszköz mérései és más mérőeszközök mérései között valóban nincs kapcsolat, ha elméleti szinten nem feltételezünk kapcsolatot a két vizsgált konstruktum között\n\n\nÚj mérőeszköz fejlesztése esetén általában már validált, a szakmában elfogadott mérőeszközökhöz hasonlítunk\n\nPrediktív validitás\n\nA mérőeszközünk mérései alapján előre tudunk jelezni más, a mért dologgal összefüggő egyéb kimeneteleket\n\nPl: ha feltételezzük, hogy a figyelmetlenség összefügg a pénzszórással, akkor azt várjuk, hogy aki a figyelmetlenségi kérdőíven magas pontszámot ér el, átlagosan jobban fogja szórni a pénzt a hétköznapokban\n\n\n\n\n\n\n\n3.2.2 Milyen pontossággal mérünk?\n\nMinden mérésben van mérési hiba\nÁltalában ezt akarjuk csökkenteni\nMegtehetjük:\n\nMérőeszköz minőségének javításával\nMég több méréssel\n\nMegbízhatóság (reliabilitás)\n\nAzt mutatja meg, hogy mennyire pontosan, konzisztensen mér a merőeszközünk\nTeszt-retesz megbízhatóság\n\nHa többször megismételjük a mérést, mennyire járnak együtt a mérések eredményei\n\nMegbízhatóság fontos, ha össze akarunk több mérést hasonlítani\n\nKét változó közötti kapcsolat nem lehet erősebb, mint egy változó és önmaga közötti kapcsolat (másnéven a változó megbízhatósága)\nNem megbízható mérés nem tud erős statisztikai összefüggésben lenni egy másik méréssel\n\n\n\n\n\n3.2.3 A változók mérési szintjei\n\nHogyan viszonyulnak egymáshoz a változó értékei\nFolytonos vagy diszkrét változók\n\nFolytonos: bármilyen értéket felvehet egy bizonyos értéktartományban\nDiszkrét: csak bizonyos értékeket vehet fel\n\nNégy szempont alapján térhetnek el:\n\nEgyediség: a változó minden értéke egyedi jelentéssel rendelkezik\nSorbarendezhetőség: sorba rendezhetők-e a változó értékei valamilyen szempont alapján\nEgyenlő távolság: az egyes értékek közötti távolság a skála minden pontján egyenlő\n\n1cm és 2cm között ugyanakkora a távolság, mint 12cm és 13cm között\n\nAbszolút nulla pont: van-e a skálának abszolút nulla pontja.\n\nPéldául súly vagy magasság\n\n\nEzek alapján a következő mérési szintekről beszélhetünk:\n\nNominális skála\n\nA skálának minden tagja egy egyedi értéket jelöl\nA skálában lévő számok kvalitatív értékek címkézésére vannak\nNem rakhatók nagyságrendileg sorrendbe, nincs nulla pontjuk, a köztük lévő távolság értelmezhetetlen\nMatematikai módszerek: összehasonlíthatók\nStatisztikai módszerek: módusz\nDiszkrét\nLegtöbbször az adattáblában egész számokkal vagy szöveggel jelöljük\n\nAz egész számok csak jelző címkeként szolgálnak, algebrai műveletek nem végezhetők rajtuk\n\n\nOrdinális skála\n\nÉrtékei egyediek és sorbarendezhetők\nDe az értékek közötti távolság értelmezhetetlen\nPl: fájdalom mérésére szolgáló skála\n\nA Likert-típusú skálánál például elmondható, hogy a “Teljesen egyetértek” pozitívabb, mint az “Inkább egyetértek”, de a kettő közti távolság nem kvantifikálható. Ezért nem tudunk Likert-típusú skáláknál átlagot számolni.\n\nMatematikai módszerek: megnézhetjük, hogy az egyik érték nagyobb-e a másiknál\nStatisztikai módszerek: medián\nDiszkrét\nAz adattáblában általában egész számokkal jelöljük őket\n\nIntervallum skála\n\nAz ordinális skálánál több, amennyiben a felvehető értékek közötti távolság állandó\nPl: hőfok Celsiusban\nMatematikai módszerek: összeadhatjuk vagy kivonhatjuk\nStatisztikai módszerek: átlag\nFolytonos\nAz adattáblában egyész számokkal vagy valós számokkal jelöljük őket\n\n Arány skála\n\nAz interval skálán felül van értelmezhető abszolút 0 pontja.\nPl: Súly és magasság\nMatematikai módszerek: szorozhatjuk vagy oszthatjuk\nStatisztikai módszerek: átlag\nFolytonos\nAz adattáblában egyész számokkal vagy valós számokkal jelöljük őket\n\n\n\n\n\n3.2.4 Mérési skálák hatása a statisztikai tesztek előfeltételeire\n\nA változók mérési szintjei meghatározzák, hogy milyen matematikai/statisztikai módszereket alkalmazhatunk rajtuk és így végül milyen kérdéseket tudunk általuk megválaszolni\nA változók mérési szintjei együtt járnak a mérési skálák granularitásával\n\nGranularitás: változó szintjeinek száma, azaz hány lehetséges értéket tud felvenni a változó\n\nPéldául a fájdalmat mérhetjük úgy, hogy:\n\nVizuális analóg skálánál a végpontok vannak megadva (nincs fájdalom - legerősebb elképzelhető fájdalom) közte 1-100-ig bejelölhetik a résztvevők az átélt fájdalmuk\nLikert-típusú skálán is mérhetjük, aminek három szintje van és mindegyik szinthez egy leíró címke tartozik (1 - egyáltalán nem fáj, 2- közepesen fáj, 3 - nagyon fáj)\nNumerikus skálán is mérhetjük, aminek 11 szintje (0 - 10) van az első ötödik és tizedik szinteken leíró címkével\n\nHa egy skála granularitása kicsi (&lt;12) vagy minden szintjéhez címke tartozik, nem kezelhetjük intervallum skálaként\n\nTehát nem számolhatunk átlagot\n\nMérési skálák granularitását növelhetjük az itemek számával\n\nPl: Több 7 fokú válasz skálás kérdéssel mérjük ugyanazt a konstruktumot\n\nA válaszokat összesítjük (például összeadás vagy átlagolás útján)"
  },
  {
    "objectID": "data.html#hogyan-struktúráljuk-az-adatokat",
    "href": "data.html#hogyan-struktúráljuk-az-adatokat",
    "title": "3  Adat",
    "section": "3.3 Hogyan struktúráljuk az adatokat?",
    "text": "3.3 Hogyan struktúráljuk az adatokat?\n\nAz adatok különböző formátumban léteznek\n\nKérdőíves felmérések adatai, orvosi MRI képek, banki tranzakciók lenyomatai, twitter megosztások száma, egy adott időszakban megjelent publicisztikák\n\nA nyers adatok kinyerése és tisztítása teszi ki általában az adatelemzői munka nagy részét a statisztikai elemzéshez képest\nAz egyszerűség kedvéért az órán adattáblákkal fogunk dolgozni\nAz adattábla változók és megfigyelések összessége\n\nAdatpont (data point): egy mérésből származó érték, pl. egy ember egy válasza egy kérdésre\n\ncellák\n\nMegfigyelés (observation): ugyanannak a megfigyelési egységnek (pl. egy ember) az összes adatpontja (pl. összes kérdésre adott válasza)\n\nsorok\n\nVáltozó (variable): több megfigyelési egységnek az ugyanarra a mérésre adott értékei\n\nOszlopok\n\n\n\n\n3.3.1 Milyen egy jó adattábla?\n\n“négyzetes”: a sorok és oszlopok következetes módon megfigyeléseket és változókat jelentenek\nA változónevek emberi és gépi olvasásra is alkalmasak\n\nminél rövidebb, a változónevek mindig angolul, ékezetek nélkül, szóközök nélkül legyenek írva, legyen egyértelmű jelentésük, pl. education, bdi_1, bdi_sum\n\nVáltozónevek egy táblán belül következetesen legyenek használva\n\nLásd: snake_case vagy camelCase\nAzonos információ egységek azonos helyen legyenek elszeparálva\n\nquestion_01_item_01, question_01_item_02\nÉs nem: question01_item_01, question_01_item02\n\n\nA címkék szó szerint szerepelnek, és nem kódolva (pl. a kategorikus adatokhoz)\n\n“férfi”, és nem 1)\n\nA változó egy információt tartalmaz a megfigyelésről\n\n“Férfi 18-29” az két információ\n\nMinden információ explicit adat (és nem formázási mód vagy komment)\nA hiányzó adat hiányzó cella, nem pedig pl. -999\nMinden megfigyelési egységnek (pl. résztvevő) egyedi azonosítója van\nVan hozzá “kódkönyv” (code book vagy data dictionary)\n\nEz szintén legyen ember és gépi olvasásra alkalmas\nInformáció az adatok formátumáról (pl. adattábla x sorral és y változóval)\nVáltozók jelentése, mértékegysége, típusa, a változó hogyan lett kiszámítva\nInformáció az adatgyűjtés módszeréről\n\nVáltozón belül az értékek konzisztensen azonos típusúak és jelölésűek legyenek\n\nRossz példa: férfi, Férfi, nő, female\n\nFigyeljünk a kis és nagybetűkre!\nSzámozási sorrendnél használjunk vezető 0-át\n\nPl: 01, 02, 03, 11, 12\nÉs nem: 1, 11, 12, 2, 3"
  },
  {
    "objectID": "data.html#hogyan-dolgozzunk-az-adatokkal",
    "href": "data.html#hogyan-dolgozzunk-az-adatokkal",
    "title": "3  Adat",
    "section": "3.4 Hogyan dolgozzunk az adatokkal?",
    "text": "3.4 Hogyan dolgozzunk az adatokkal?\n\nAdatrendezés alapelvei\n\nNem törlünk ki adatokat\nAdatállomány feldolgozottsági szintjei szerinti felosztás\n\nSource: forrás adatok, ahogy a mérőeszközünk visszaadja az adatokat bármilyen beavatkozás nélkül, sokszor tartalmaz olyan adatokat, amelyek a résztvevők beazonosítását lehetővé teszik\n\na forrás adatok nyílt hozzáférésű megosztása ebben az esetben tilos\n\nRaw: nyers adatok, lényeges beavatkozás nem történt az adatfájlon, változó nevek lettek standardizálva, fájl formátuma lett megváltoztatva, a beazonosítást lehetővé tevő változók lettek maszkolva vagy kitörölve\nProcessed: feldolgozott adatok, az adatszűrés és szükséges transzformációk után\n\nNem módosítjuk az eredeti állományt, legfeljebb a másolato(ka)t\nHa lehet, készítsünk adatkezelési tervet (data management plan)\n\nSok pénzügyi támogató elvárja már!\nBiztosíthatjuk vele, hogy nem követünk el adatkezelési hibákat\nHogyan készítsünk jó adatkezelési tervet?\n\nhttps://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004525"
  },
  {
    "objectID": "data.html#adatkezelési-hibák",
    "href": "data.html#adatkezelési-hibák",
    "title": "3  Adat",
    "section": "3.5 Adatkezelési hibák",
    "text": "3.5 Adatkezelési hibák\n\nÁltalában arról hallunk a médiában, ha egy kutatót adahamisítással lepleznek le\nKevesebb szó esik az adatkezelési hibákról, pedig feltételezhetően ezek sokkal gyakrabban fordulnak elő\nAz adatkezelési hibákat sokszor akaratlanul követik el a kutatók\nAz adatkezelési hibáknak lehetnek súlyos következményei\n\nmegváltoztathatják például az adatokből levont köveztetéseket\n\nReinhart & Rogoff (2010) közgazdászok például a kimutatták, hogy egy állam valós gazdasági növekedése lelassul, ha az államtartozás a GDP 90%-át meghaladja\n\nEredményeik az USA költségvetési tervébe is bekerült\nKésőbb kiderült, hogy nem jelölték ki az összes adatsort az elemzés során, így a vizsgált adatoknak csak egy része került elemzésre\nAz újraelemzés az eredeti követeztetéseket invalidálta\n\nAz adatkezelési hibák nagy része az emberi hibából (human error) fakad\n\nKognitív kapacitásaink végesek, elfáradunk, nyomás alatt rosszabbul teljesítünk, stb.\n\nEzért fontos olyan adatkezelési rendszert kiépíteni, amely ezen hibák előfordulási valószínűségét csökkenti\nTovábbi olvasmányok:\n\nhttps://journals.sagepub.com/doi/full/10.1177/25152459211045930\nhttps://www.nber.org/papers/w15639"
  },
  {
    "objectID": "descriptive_statistics.html#értékek-eloszlása",
    "href": "descriptive_statistics.html#értékek-eloszlása",
    "title": "4  Leíró statisztika",
    "section": "4.1 Értékek eloszlása",
    "text": "4.1 Értékek eloszlása\n\nAz adatok leírásának egyik módja az eloszlásuk vizsgálata\n\nEz alapján meg tudjuk mondani, hogy mely értékek gyakoriak és melyek ritkák az adattáblánkban\n\nAz eloszlás megmondja, hogyan oszlik meg az adat a különböző lehetséges értékek között\n\nPéldául: diszkrét változó esetén hányan választották az egyes lehetséges opciókat\n\nAz egyik gyakran vizsgált eloszlás fajta a gyakorisági eloszlás\n\nA gyakorisági eloszlás megmondja, hogy egy változó lehetséges értékei milyen gyakran fordulnak elő a mintánkban\nDiszkrét változó gyakorisági eloszlása\n\nPélda\n\nPélda…\n\nEz a táblázat az adatok abszolút frekvenciáját mutatja meg\nAhhoz, hogy meg tudjuk mondani a gyakoriságok között különbség valóban lényeges-e hasznos lehet megtekinteni a relatív frekvenciájukat (sűrűségüket)\nEhhez minden lehetséges értékhez el kell osztani az abszolút gyakoriságot a változóban található összes érték számával\n\nHogyan ábrázoljuk a gyakoriságot?\n\nDotplot\n\nMinden értéket egy pötty jelöl\nAz x tengely az értéktartomány\nAz y tengely a gyakoriság\nFolytonos változónál az összesítés során az értéktartományt különböző méretű “vödrökre” osztjuk\nMeghatározzuk a vödrök szélességét (binwidth)\nÉs az ebbe az értéktartományba eső értékek gyakoriságát számoljuk meg és ábrázoljuk\n\nA hisztogram hasonló, mint a dotplot\n\nDe az egyes értékek nem jelennek meg külön, így sok adat gyakoriságát egyszerre tudjuk ábrázolni\n\n\n\nKumulatív gyakorisági eloszlás\n\nAzon értékek gyakorisága amelyek akkor vagy kevesebbek, mint az adott határérték, amit vizsgálunk\nKiszámolásához összeadjuk a hátárétrék gyakoriságát és az összes nála kisebb érték gyakoriságát\nÉrtéke soha nem csökkenhet\npélda"
  },
  {
    "objectID": "descriptive_statistics.html#statisztikai-modellek",
    "href": "descriptive_statistics.html#statisztikai-modellek",
    "title": "4  Leíró statisztika",
    "section": "4.2 Statisztikai modellek",
    "text": "4.2 Statisztikai modellek\n\nLeegyszerüsített reprezentációja az adatoknak\nLeírja az adatok struktúráját\nMindig van benne hiba faktor, kihagy részleteket\n“All models are wrong but some are useful” (George Box)\nA statisztikai modellre gondolhatunk úgy is, mint egy elméletre, amely leírja hogyan keletkeztek az adatok\nCélunk: olyan modellt alkossunk, ami hatékonyan és pontosan írja le az adatok keletkezésének a módját\n\nMásszóval, fontos, hogy a modell jól illeszkedjen az adatokra\n\nMinél jobban illeszkedik a modell az adatokhoz (a valósághoz), annál megbízhatóbbak a modell által létrehozott predikciók\n\n\n\nMivel minden modell a valóság leegyszerüsítése, így az soha nem fogja tökéletesen reprezentálni a valóságot\n\nlesz hiba a modell által prediktált értékek és az egyes megfigyelések között\nAdat = modell + hiba\n\nModell: az értékek, amit az elméletünk alapján elvárunk\nHiba: a modell által prediktált értékek és a valós adatpontok közötti különbség\n\n\n\n4.2.1 A legegyszerűbb statisztika modell, az átlag\n\nMinden megfigyelésre ugyanazt az értéket prediktálja\nPélda\n\nVizsgálhatjuk például, hogy a statisztika tanároknak hány barátja van\nTegyük fel, hogy 5 tanárt kérdezünk meg\nAz átlag: (1 + 2 + 3 + 3 + 4)/5 = 2.6\nEbből is látszik, hogy az átlag egy statisztikai modell, hiszen egy hipotetikus érték, nem megfigyelhető a valóságban\n\n\n\n\n4.2.2 Modell illeszkedésének a vizsgálata\n\nHogyan tudjuk megvizsgálni, hogy mennyire jól illeszkedik az átlag, mint modell, az adatokra?\n\nAhhoz, hogy eldöntsük a modell jól írja-e le az adatokat, megnézhetjük a megfigyelt adatok és a modell értékei közötti különbséget\nEzen értékek közötti eltérés a modell hibája\nPéldául annál a kutatónál, akinek egy barátja van, a modell 2.6 barátot prediktál (ez volt az átlag), a modell hibája, azaz az eltérés, így megfigyelt értél - prediktált érték = -1.6\nEbben az esetben a modell felül becsüli a kutató népszerűségét!\nHogyan összesítsük az egyes eltéréseket, hogy meg tudjuk határozni a modellünk pontosságát?\n\nPéldául összeadhatjuk őket (sum of errors)\n\nEbben az esetben azt látjuk, hogy az eltérések összege 0\nEz alapján arra következtethetnénk, hogy az átlag tökéletesen reprezentálja az adatokat, azonban az ábrára ránézve láthatjuk, hogy ez nem így van\n\naz egyes értékek és a modell által prediktált értékek között van különbség\n\nMég egy ok az ábrázolás fontossága mellett!\n\n\nA negatív és a pozitív előjelű eltérések kiegyenlítették egymást\n\nEzt elkerülendő négyzetre emelhetjük az eltéréseket az összeadás előtt (sum of squared errors)\n\nÍgy minden eltérés előjele pozitív lesz\nA példánkban a négyzetes eltérések összege 5.20\nMost azonban abba a problémába ütközünk, hogy a modell pontosságának mérője függ a mintánk méretétől\nMinél több megfigyelésünk van, annál nagyobb lesz a modell hiba\n\nEzt elkerülhetjük úgy, hogy összeadás helyett a négyzetes eltérések átlagát vesszük (mean of squared errors)\n\nEhhez elosztjuk a négyzetes eltérések összegét a megfigyelések számával\nÍgy azonban csak a mintánkban lévő átlagos hibát számszerüsítjük\nAzonban célunk, hogy a mintában lévő hibából a populációban található hibát becsüljük meg\nEhhez a minta mérete helyett a szabadságfokkal kell elosztanunk a négyzetes eltérések összegét\nJelen esetben ez n - 1\n\nEzt nevezzük varianciának\n\nÁtlagos négyzetes eltérés az átlagtól\nA varianciával a probléma, hogy a mértékegysége az adatok skálájának négyzete\nA példánkban 1.3\n\nNégyzetes barátok száma nehezen értelmezhető!\n\n\nEzt elkerülhetjük úgy, hogy a variancia gyökét vesszük, ez a szórás\n\nÍgy a modell hibájának mérője ugyanazt a skálát használja, mint a megfigyeléseink\nAz átlaghoz képest kis szórás azt mutatja, hogy a modellunk jól illeszkedik az adatokra\n\nA megfigyelések közel vannak az átlaghoz\n\nPélda\n\nMegkérhetjük a hallgatókat, hogy egy 5-ös skálán értékeljék az egyes statisztika oktatókat\nA mérést elvégezhetjük 5 egymást követő órán\nAz ábrán két oktatónak öt óráján mért összesített értékelései láthatók\nHa az átlagot használjuk, mint statisztikai modellt, mind a két oktatónál ugyanazt az átlagot kapjuk\nMégis látható, hogy az egyik oktatónál a modell jobban illeszkedik az adatokhoz, tehát az átlag pontos reprezentációja az adatoknak\n\nEzt mutatja, hogy a szórás 0.55 az átlaghoz mérten kicsi\n\n\n\n\n\n\n\n\n4.2.3 Mitől jó egy statisztikai modell?\n\n1) kicsi a hiba\n\nMitől lehet nagy a hiba?\n\nRossz a modell\n\nKimaradt egy fontos prediktor változó\nA prediktor változó hatásának irányát rosszul adtuk meg\n\nPl: azt feltételezi a modell minél idősebb valaki annál alacsonyabb gyerekek körében\n\nAz adatok vizualizációja fontos, hogy jól specifikált modellt tudjunk építeni\n\nMérés hiba/zaj/adatokban lévő variancia miatt\n\nVagy a mérőeszköz nem elég pontos\nVagy egyébb faktorok is befolyásolják a megfigyelt mérésekben lévő varianciát, amikről nem tudunk vagy nem tudjuk mérni\n\n\n\n2) jól generalizálható\n\nha új adatokra illesztjük a modellt, azokat is jól fogja prediktálni"
  },
  {
    "objectID": "descriptive_statistics.html#összesítő-statisztikák",
    "href": "descriptive_statistics.html#összesítő-statisztikák",
    "title": "4  Leíró statisztika",
    "section": "4.3 Összesítő statisztikák",
    "text": "4.3 Összesítő statisztikák\n\nGyakoriság (frequency): a megfigyelések száma (db). Pl. az előadást megnéző hallgatók száma.\nÖsszeg (summary): egy változó összes értékének összeadásával keletkező érték. Pl. covid megbetegedések száma.\nArány (proportion): a megfigyelések száma az összes megfigyeléshez képest (Pl. 54 % vagy 0.54 vagy .54). pl. biciklisek aránya az összes közlekedőhöz képest az Andrássy úton\n\n\n4.3.1 Középértékek\n\nMatematikai átlag (mean, average): Az értékek összege elosztva az értékek számával\n\nÁltalában folytonos változóknál vagy nagy granilaritással rendelkező ordinális változónál használjuk\nAkkor jó használni, ha a változónk eloszlása szimmetrikus\nHa nagy kiugró értékek vannak az átlag torzíthat\n\nAz átlag a négyzetes hibák összegét csökkenti\nA hibák négyzetre emelésénél a kiugró értékeknél exponenciálisan nő a hiba\n\n\nMedián (median): A nagyság szerint sorba rendezett értékek közül a középső. Ha páros számú érték van, akkor általában a középső kettő átlaga\n\nOrdinális változónál használjuk\nAkkor jó használni, ha ferde az eloszlás vagy vannak outlierek\n\nA hibák abszolút értékének összegét csökkenti\nEzért kevésbé érzékeny, nincs négyzetre emelés\n\n\nMódusz (mode): A leggyakrabban előforduló érték\n\nNominális változónál használjuk\n\n\n\n\n4.3.2 Szélsőértékek\n\nMinimum: a legkisebb érték\nMaximum: a legnagyobb érték\nKiugró értékek (outlier): olyan érték, ami a többitől távol esik\n\nAzt, hogy milyen vágási ponttól számít egy érték outliernek sokszor nem könnyen határozható meg.\nFügghet az elmélettől vagy az adott szakterületen használt konvenciók is megszabhatják\nAz outlierek nagy torzító hatással vannak az átlagra\n\nÉrdemes ezért megvizsgálni a változónk eloszlását, mielőtt úgy döntünk, hogy az átlag alapján kívánjuk összesíteni az adatainkat\n\nLehet, hogy torzítani fog = nem jól reprezentálja az adatokat\n\n\nKevésbé torzítják a mediánt\nNem torzítják a móduszt\n\n\n\n\n4.3.3 Helyzetmutatók\n\nKvantilisek: vágási pontok, amelyek mentén a sorba rendezett adatokat meghatározott számú részre bonthatjuk\nPl. kvartilisek: Az adatokat négy egyenlő részre osztó három pont (ld. még decilis, percentilis)\nInterkvartilis tartomány (IQR): A felső (75%) alsó (25%) kvartilis és az alsó kvartilis különbsége, az adatok középső 50%-a \n\nÁltalában ordinális adatok összesítésénél szoktuk használni"
  },
  {
    "objectID": "visualization.html#a-jó-adatvizualizáció-ismérvei",
    "href": "visualization.html#a-jó-adatvizualizáció-ismérvei",
    "title": "5  Adatvizualizáció",
    "section": "5.1 A jó adatvizualizáció ismérvei",
    "text": "5.1 A jó adatvizualizáció ismérvei\n\nAz ábra minden részének legyen információ értéke\n\nFelesleges vagy redundáns elemek ne kerüljenek rá, mert elterelik a figyelmet a lényegről és megzavarják az értelmezést\nOlyan elemek jelenjenek meg csak az ábrán, amelyek nem törölhetők információ veszteség nélkül\nLásd:\n\nadat/tinta arány\nÁbra szemét\n\n\nLegjobb megmutatni az egyéni adatpontokat is amennyiben ez lehetséges\n\nAz összesítés torzíthatja az eredményeket\n\nHasználd ki az ábránál a teret, de figyelj rá, hogy közben ne torzítsd az adatokat\n\nKülönböző ábrázolási módok nagyon más történetet tudnak elmesélni\nPélda: szerepeljen-e a nulla érték az y tengelyen vagy ne\n\nFigyelj az emberi percepció limitációira\n\nSzínvakság\n\nHasználj színvak barát színeket\n\nPie chart\n\nAz embereknek ennél a vizualizációs módszernél nagyon nehéz az arányokat helyesen értelmezni!\nNe használjuk!"
  },
  {
    "objectID": "visualization.html#gyakori-adatvizualizációs-megoldások",
    "href": "visualization.html#gyakori-adatvizualizációs-megoldások",
    "title": "5  Adatvizualizáció",
    "section": "5.2 Gyakori adatvizualizációs megoldások",
    "text": "5.2 Gyakori adatvizualizációs megoldások\n\n5.2.1 Doboz ábra (boxplot)\n\nA helyzetmutatókat általában egy boxplot segítségével vizualizáljuk\nAhol a doboz felső határsa a 75-ik percentilist, az alsó határa a 25-ik percentilist jelöli\n\nA két vonal közötti rész az IQR\n\nA kettő közti vonal a doboz felénél az 50-ik percentilist jelöli\n\nMásnéven medián\n\nA dobozból kijövő függőleges vonalak a 75-ik és a 25-ik percentileseken kívül eső, de még nem outlier értékeket mutatják\n\nEzen kívül pöttyökkel tudjuk jelölni azokat az egyes adatpontokat, amelyek outlier értéknek számítanak"
  },
  {
    "objectID": "visualization.html#hogyan-szúrjunk-ki-megtévesztő-vizualalizációs-elemeket",
    "href": "visualization.html#hogyan-szúrjunk-ki-megtévesztő-vizualalizációs-elemeket",
    "title": "5  Adatvizualizáció",
    "section": "5.3 Hogyan szúrjunk ki megtévesztő vizualalizációs elemeket?",
    "text": "5.3 Hogyan szúrjunk ki megtévesztő vizualalizációs elemeket?\n\nSegít-e az ábra megérteni az adatokat, vagy inkább csak összezavar?\nFigyelmesen nézd meg az ábrán a tengelyek nevét és léptékét!\nNézd meg, hogy a tengelyek a nulláról indulnak-e! \nNézd meg, hogy a különböző csoportokat bemutató ábrázolások egyenlő arányban változnak-e egymással\nNem hagytak-e ki adatpontot az ábráról?\nÖsszevontak-e kategóriákat indokolatlanul?\nSzerepelnek-e olyan adatcsoportok az ábrán, amelyek önkényesen lettek kiválasztva?\nPéldák rossz ábrákra\n\nhttps://venngage.com/blog/misleading-graphs/"
  },
  {
    "objectID": "inferential_statistics.html#mintavételezés",
    "href": "inferential_statistics.html#mintavételezés",
    "title": "6  Következtetéses statisztika",
    "section": "6.1 Mintavételezés",
    "text": "6.1 Mintavételezés\n\nA minta kiválasztásának módja fontos, mert ezzel tudjuk biztosítani, hogy a minta jól reprezentálja a populációnkat\n\nvalószínűségi mintavételezés: minta jól reprezentálja a populációt, ha a populáció minden tagjának egyenlő esélye van a mintánkba való bekerülésre\nkvóta: a populáció néhány ismert jellemzője alapján válogatunk be meghatározott számú résztvevőt  (pl. 50-50% nő és férfi)\nkényelmi: az vesz részt a kutatásban, akit éppen elérünk\n\nA mintavételezés előnyei és nehézségei\n\nelőnyei\n\nmáshogy nem tudunk információhoz jutni az egész populációra vonatkozóan\ntudunk becsléseket tenni  a populáció jellemzőire (“valódi” átlag, szórás, eloszlás, stb.)\nha ismerjük a hátulütőket, tudjuk kommunikálni a bizonytalanságot is\n\nnehézségei\n\na minta soha nem tökéletes reprezentációja a populációnak, azaz mindig valamennyire torzított\na kisebb minták könnyebben torzítottak, mint a nagyobbak\nnem lehet pontosan tudni, hogy a minta elég jól reprezentálja-e a populációt\nlehet, hogy a minta alapján téves következtetésre jutunk a populációra vonatkozóan\n\n\n\n\n6.1.1 Standard hiba\n\nAttól függetlenül, hogy milyen nagy elővigyázatossággal választottuk ki a mintánkat, a minta különbözni fog a populációtól\n\nEz a mintavételezési hiba (sampling variation)\n\nAbból következik, hogy a populáció összes egyedéből véletlenszerűen választunk ki egyedeket a mintánkba\n\n\nHa többször veszünk mintát egy adott populációból hosszútávon elvárható, hogy a mintáink átlagai leggyakrabban a populáció átlag körül fognak csoportosulni\n\nA minta átlagok eloszlását a mintavételi eloszlásnak (sampling distribution) hívjuk\n\nA mintaátlagok gyakorisági eloszlása\nHa a minta átlagok átlagát vennénk a populáció átlagot kapnánk meg\n\nA minta átlagok populáció átlag körüli szóródását a standard hibával írjuk le\n\nMáshogyan: Azt a bizonytalanságot fejezi ki, amiben a populációátlagtól eltérhet a mintaátlagtól\n\nPontosabb nevén az átlag standard hibája (standard error of the mean).\nKiszámolásához a minta szórását elosztjuk az elemszám négyzetgyökével\nA standard hiba alapján a mérésünk minősége a populációban található variabilitástól és a mintánk méretétől függ\n\nMivel csak a minta méretre van ráhatásunk ennek növelésével javíthatjuk a mérőeszközünk pontosságát\nMinél nagyobb a mintaméret, annál biztosabbak lehetünk abban, hogy a populációátlagot jól közelítjük\n\nAzonban nem csak a minta mérete számít, hanem a mintavételezés módja is\n\nAkármilyen nagy a mintánk, ha annak tagjai nem jól írják le a populációt mert a minta szisztematikusan torzít\nEzért szoktak kutatók általában random mintavételezésre törekedni\n\n\n\nÁltalában ezt szokták az ábrákon megjeleníteni hibasávként (error bar)\nHa a hibasávok nem fednek át, akkor arra következtethetünk, hogy a populációban lévő különbség valódi\n\n\n\n\n6.1.2 Centrális határeloszlás elve\n\nCentral limit theorem (CHE)\nA mintaméret növekedésével a mintaátlagok eloszlása közelít a normális eloszláshoz.\nEz akkor is igaz, ha az egyes mintákban lévő eloszlások értéke nem normális!\nDemonstráció: https://istats.shinyapps.io/sampdist_cont/\nA CHE miatt használhatjuk a legtöbb statisztikai módszert ami normális eloszlást feltételez"
  },
  {
    "objectID": "inferential_statistics.html#konfidencia-intervallum",
    "href": "inferential_statistics.html#konfidencia-intervallum",
    "title": "6  Következtetéses statisztika",
    "section": "6.2 Konfidencia intervallum",
    "text": "6.2 Konfidencia intervallum\n\nAhogy már korábban említettük a minta átlagát használjuk arra, hogy megbecsüljük a populáció átlagot\n\nEzzel az adatokból levont következtetést általánosítsuk (generalization) a mintánkon túlra\n\nLáttuk, hogy különböző mintavételelezések különböző minta átlagokat adnak és a standard hibát használhatjuk arra, hogy meghatározzuk mekkora a mintaátlagok varianciája a populáció átlag körül\nAzt, hogy a minta átlag mennyire jól becsüli meg a populáció értéket úgy is eldönthetjük, hogy kiválasztunk egy értéktartományt, amelybe a populáció átlag feltehetően beleesik\n\nEzt az értéktartományt nevezzük konfidencia intervallumnak\n\nMinél szélesebb a konfidencia intervallumunk annál bizonytalanabbak vagyunk abban, hogy a minta átlag jó reprezentációja-e a populáció átlagnak\n\n\n6.2.1 Helyes értelmezése\n\nA konfidencia intervallumot gyakran félreértik a kutatók\n\nTalán még a p értéknél is gyakrabban!\n\nEgy 95%-os konfidencia intervallum nem azt jelenti, hogy 95% az esélye annak, hogy a populáció átlaga beleesik-e az intervallumba!\n\nA populáció átlag egy fix érték, így egyes esetekben vagy beleesik vagy nem\nNem tudunk valószínűséget rendelni mellé\n\nA helyes értelmezésnél ugyanazt a logikát kell követnünk, mint a hipotézis tesztelésnél: hosszútávon milyen valószínűséggel fogunk helyes döntést hozni\n\nhosszútávon a konfidencia intervallum az esetek 95%-ában fogja tartalmazni a populáció átlagot \nha végtelenszer megismételjük a mintavételt és kiszámoljuk a minta átlagot és a hozzá tartozó konfidencia intervallumot, akkor az esetek 95%-ában a kapott konfidencia intervallumok magukba fogják foglalni a populáció átlagot\nAzt azonban nem tudhatjuk, hogy az éppen általunk gyűjtött mintához kiszámolt konfidencia intervallum tartalmazza-e a populáció átlagot vagy sem\nMásszóval: 95%-os konfidencia intervallum mellett az esetek 5%-ban tévedünk, ha feltételezzük, hogy az adott konfidencia intervallum valóban magába foglalja a populáció átlagot\n\n\n\n\n6.2.2 Kiszámítása\n\nA konfidencia intervallumot a z értékek segítségével számoljuk ki\nEgy normál eloszlásnál ahol az átlag 0 és a szórás 1 a z értékek 95%-a a -1.96 és a +1.96-os z értékek közé fog esni\nAlsó határa a konfidencia intervallumnak: minta átlag - (1.96 * standard hiba)\nFelső határa a konfidencia intervallumnak: minta átlag + (1.96 * standard hiba)\nA mintánk átlaga mindig a konfidencia intervallum közepe\nA konfidencia intervallum mérete függ a standard hiba méretétől\nHa kicsi a minta a t eloszlást használva kell kiszámítani a konfidencia intervallumot\n\n\n\n6.2.3 Vizuális ábrázolása\n\nKonfidencia intervallumok vizuális ábrázolása\n\nÁltalában a konfidencia intervallumot használjuk ábrákon az átlag körüli hiba mértékének vizualizására\nHa két átlaghoz tartozó konfidencia intervallumok átfednek, akkor feltételezhetjük, hogy a két minta átlaga ugyanabból a populációból származik\n\nLásd t-próba\n\nHa nem fednek át\n\n1) vagy különböző populációból származnak\n2) vagy ugyanabból a populációból származnak de az egyik konfidencia intervallum nem tartalmazza a populáció átlagot\n\nEz az esetek 5%-ában fordul csak elő 95%-os konfidencia intervallum mellett, ezért valószínűleg a 1) opció mellett döntünk"
  },
  {
    "objectID": "hypothesis_testing.html#null-hipotézis-szignifikancia-tesztelés",
    "href": "hypothesis_testing.html#null-hipotézis-szignifikancia-tesztelés",
    "title": "7  Null szignifikancia hipotézis tesztelés",
    "section": "7.1 Null hipotézis szignifikancia tesztelés",
    "text": "7.1 Null hipotézis szignifikancia tesztelés\n\n7.1.1 Lépései\n\nMegfogalmazunk egy alternatív hipotézist\n\nA hipotézisünknek lehet iránya (egyoldalú hipotézis tesztelés)\n\nPozitív vagy negatív kapcsolatot várunk el\nEgy oldalú hipotézis tesztelésnek is nevezik\n\nVagy lehet kétoldalú hipotézis teszt\n\nEbben az esetben az alternatív hipotézisünk csak azt várja el, hogy a lesz lesz különbség a vizsgált változók között, de az nem mondjuk meg milyen irányú különbséget várunk el\n\nAzt, hogy melyik hipotézist alkalmazzuk az elmélet (előzetes tudásunk) határozza meg\n\nMegfogalmazzuk a null hipotézist\n\nEgyoldalú hipotézis esetén a null hipotézis feltételezi, hogy az alternatív által prediktált iránnyal ellenkező előjelű különbséget kapunk vagy nem lesz különbség\nFeltételezzük, hog a null hipotézis igaz!\n\nA hipotézis tesztelésére alkalmas adatokat gyűjtünk\nAz alternatív hipotézisünket leíró statisztikai modellt illesztjük az adatokra\n\nCélunk: az alternatív hipotézis mellett szóló evidencia számszerüsítése az adatokban található variancia ellenében\nA modell illesztése során kiszámoljuk a teszt statisztikát\n\nKiszámoljuk a teszt statisztikát\n\nA teszt statisztikára gondolhatunk úgy, mint a vizsgált hatás mértetének mutatója az adatokban található variancia fényében\n\nMegvizsgáljuk, hogy milyen valószínűséggel kapnánk ilyen vagy ennél extrémebb teszt statisztikát, ha a null hipotézis igaz\n\nEhhez egy valószínűségi eloszlást használunk, ami megmutatja, hogy a null hipotézis alatt, milyen valószínűségeket várnánk el az egyes teszt statisztika értékekhez\nEhhez általában egy elméleti eloszlást használnuk, ami illik a vizsgált teszt statisztikához\n\nPéldául t tesztnél a teszt statisztika a t érték, és t-eloszlást használnuk\n\nAz így kiszámolt valószínűség a p-érték\n\nÉrtelmezzük az eredmények statisztikai szignifikanciáját\n\nA p-értéket fogjuk használni arra, hogy eldöntsük elég meglepőek-e az adataink ahhoz, hogy elvessük a null hipotézist\nEhhez egy döntési kritériumot kell használnunk, amit a szignifikancia küszöbérték, azaz alpha fog számszerűsíteni\nFontos megjegyezni, hogy nem tudhatjuk, hogy a döntés, hogy elvetjük a null hipozétist helyes vagy helytelen döntés-e egy adott esetben!\n\nVagy egyik vagy a másik nem rendelhetünk mellé valószínűséget!\n\nÍgy egyedül azt tudjuk megmondani, hogyha ilyen vagy ennél extrémebb adatokat kaptunk hosszútávon, ha végtelenszer megismételjük a kísérletet és ugyanezt a döntési kritériumot (alphat) használjuk, akkor az esetek hány százalékában fogunk hibásan dönteni\n\n\n\n\n7.1.2 Szignifikancia küszöb\n\nNincs objektíven helyes küszöbérték!\nHagyományosan a szignifikancia küszöb 0.05\n\nAz alpha = 0.05 azt mondja meg, hogyha végtelenszer megismételjük a kutatást hosszútávon 5% az esélye annak, hogy egyes fajú hibát követünk el\nEz azonban csak tradíció kérdése\nPár éve megjelent két cikk is, ami a szignifikancia küszöb újragondolására bíztat\n\nAz egyik amellett érvel, hogy hozzunk érveket amellett, hogy melyik szignifikancia küszöböt választjuk\n\nEz azonban nehéz feladat\n\nA másik amellett érvel, hogy használjunk egy konzervatívabb küszöbértéket alapértelmezettként, ami legyen 0.005\n\nEmögött az a feltételezés áll, hogy a 0.05-ös küszöbérték mellett a nullhipotézissel szembeni evidencia gyenge\n\n\n\n\n\n\n7.1.3 Mit értünk helyes döntés alatt?\n\nNégy lehetséges kimenetel létezik:\n\nElvetjük a nullhipotézist, amikor az valóban hamis\nNem vetjük el a nullhipotézist, amikor valójában igaz\nElvetjük a nullhipotézist, pedig az valójában igaz (egyes fajú hiba)\nNem vetjük el a nullhipotézist, amikor az valójában hamis (kettes fajú hiba)\n\n\n\n\nA kettes fajú hiba előfordulásának gyakoriságát a béta küszöbértékkel tudjuk kontrollálni\n\nÁltalában 0.2 azaz 20%\n\nHa az adataink kellő mértékben valószínűtlenek a null hipotézis fényében, akkor elvetjük azt és az alternatív hipotézist megtartjuk\nHa nem elég valószínűtlenek az adatok, akkor nem tudjuk elvetni a nullhipotézist\n\nEbben az esetben nem tudhatjuk, hogy a populációban valóban nem létezik a hatás vagy csak nem volt elég érzékeny a mérőeszközünk a detektálására!\n\n\n\n\n7.1.4 Többszörös tesztelés\n\nHa többször teszteljük ugyanazokat az adatokat a p érték devalválódik\nNem az egyes tesztekre kell kontrollálni a hibát, hanem a tesztek egész családjára\n\nEzt nevezzük family wise error rate-nek\n\nEzt különböző statisztikai módszerekkel tudjuk kontrollálni\n\nA legalapvetőbb a Bonferroni korrekció ahol elosztjuk az alphát a tesztek számával\n\nRészben ez magyarázza, hogy miért nem lehet az NHST alatt többszörösen tesztelni: azaz megnézni az eredményt újabb adatokat gyűjteni majd megint tesztelni\nHosszutávon a p érték biztosan szignifikáns lesz\n\nMert a nagy elemszám miatt a szórás annyira kicsire csökken, hogy kis különbséget is szignifikánsnak fogunk találni"
  },
  {
    "objectID": "hypothesis_testing.html#hatásnagyságok",
    "href": "hypothesis_testing.html#hatásnagyságok",
    "title": "7  Null szignifikancia hipotézis tesztelés",
    "section": "7.2 Hatásnagyságok",
    "text": "7.2 Hatásnagyságok\n\nA statisztikai szignifikancia nem feltétlenül jelent valós szignifikanciát\n\nPélda: egy szívritmus szabályozó gyógyszer hatékonyságának vizsgálatánál kaphatunk szignifikáns különbséget, amikor összehasonlítjuk azon résztvevők szívritmusát akik kaptak az új gyógyszerből azokéval, akik csak placebót kaptak\n\nettől függetlenül, ha a gyógyszer klinikailag nem értelmezhető módon csökkenti a szívritmus gyakoriságát (mondjuk egy gyógynövényből készült tea hatékonyságával ér fel) a gyógyszercég nem fog pénzt költeni az új gyógyszer piacra dobására\n\n\nA hatásméret (effect size) annak a számszerűsített mutatója, mennyire erős egy összefüggés, vagy mennyire nagy a különbség két csoport között\nVannak nyers hatásméret mutatók\n\nAmik ugyanazt a skálát használják, mint az adatok\nKülönböző skálákon mért hatásméretek így nem összehasonlíthatók\nAzonban a hatás valós szignifikanciájának értelmezése könnyebb velük!\n\nÉs standardizált hatásméret mutatók\n\nLehetővé teszi az összehasonlítást!\n\nLásd: metaanalízis\n\nKét család:\n\nCsoportok közötti különbségekre\n\nCohen’s d\n\nVáltozók közötti összefüggésre\n\nKorreláció, odds ratio, risk ratio"
  },
  {
    "objectID": "hypothesis_testing.html#mintaméret-és-annak-becslése",
    "href": "hypothesis_testing.html#mintaméret-és-annak-becslése",
    "title": "7  Null szignifikancia hipotézis tesztelés",
    "section": "7.3 Mintaméret és annak becslése",
    "text": "7.3 Mintaméret és annak becslése\n\nMintaméret: az egymástól független megfigyelések száma\nBefolyásolja a statisztikai erőt: annak valószínűsége, hogy megtaláljuk a hatást, amennyiben az a valóságban is létezik\n\nA kettes fajú hiba inverze\n\nNegatív eredmények esetében fontos a statisztikai erő\n\nKülönben nem tudjuk megmondani hogy valóban nem létezik a hatás vagy csak nem volt elég nagy a mintánk, hogy egy ekkora hatást észleljünk (nem volt elég érzékeny a mérésünk)\n\nA szükséges mintaméret becslést az NHST alatt a priori mintaméret becsléssel végezzük\n\nAz a priori azt jelenti, hogy csak akkor van értelme a mintaméret becslésnek, ha az az adatok gyűjtése és a statisztikai teszt elvégzése előtt történt\n\nEzután vagy megtaláltuk a hatást vagy nem, a kérdés el van döntve\nOlyan a post hoc mintaméret becslés mintha azután próbálnánk meg kiszámolni, hogy mennyi üzemanyag kell egy repülőbe ahhoz, hogy átrepüljünk vele az óceán felett, miután már megtörtént a repülés. A gép vagy lezuhant vagy nem\n\nEhhez kell az elvárt hatásméret, a kívánt statisztikai erő, a szignifikancia küszöb, a kutatási elrendezés\nMinél kisebb az elvárt hatás annál nagyobb mintára lesz szükségünk, hogy észleljük\nAz elvárt hatásméret megbecslésére számos módszer van\n\nHasználhatunk pilot kutatást\nTámaszkodhatunk a szakirodalomban előzetesen talált hatásméretekre\n\nAzonban itt lehetséges, hogy a publikált hatásméretek torzítanak!\n\nElméleti alapon is meghatározhatjuk a számunkra releváns legkisebb hatást\n\nsmallest effect size of interest (SESOI)\nmelyik az a legkisebb hatás, ami számunkra még érdekes lehet"
  },
  {
    "objectID": "correlation.html",
    "href": "correlation.html",
    "title": "8  Két folytonos változó közti összefüggés",
    "section": "",
    "text": "Statisztikai próbája a korreláció\nTeszt értéke a korrelációs együttható (r)\n\nskálafüggetlen \n-1 és 1 közötti értéket vehet fel a korreláció irányának függvényében\n\nLineáris összefüggést feltételez a két változó között\n\nPozitív: egyik változó nő a másik is nő\nNegatív: egyik változó nő a másik csökken\n\nÖsszefüggés erősségeként lehet értelmezni az r nagyságát\n\nMinél nagyobb annál erősebb az összefüggés\n\n3 típusa van\n\nPearson korreláció:\n\nLegalább intervallum típusú változók\nVáltozók eloszlása normál eloszlást követ\n\nSpearman rang korreláció:\n\nLegalább ordinális típusú változók\n\nKendall tau:\n\nLegalább ordinális\nAlacsonyabb mintaelemszámnál is jó\nJól kezeli ha sok azonos rangú elem van\n\n\nKorreláció null hipotézis tesztje\n\nKritikus értéknél az r-t t-értékké transzformáljuk\nSzabadságfok: n-2\nExcelben nem annyira egyszerű kiszámítani a korrelációs együtthatóhoz tartozó p-értéket, ezért ezen az órán ettől eltekintünk és a korrelációs együttható, mint két folytonos változó közötti kapcsolat erősségét és irányát kifejező mutató értelmezésére koncentrálunk\n\nKorrelációs mátrix\n\nTöbb változó között egyszerre mutatja meg a korrelációs együtthatókat táblázat formájában\n\nKorrelációs együttható négyzete a determinisztikus együttható (R2)\n\nEgyik változó mekkora részt magyaráz a másik változóból\nA variance mekkora részét magyarázza meg\nRegressziónál fontos mutató"
  },
  {
    "objectID": "regression.html#egyszerű-lineáris-regresszió",
    "href": "regression.html#egyszerű-lineáris-regresszió",
    "title": "9  Lineáris regresszió",
    "section": "9.1 Egyszerű lineáris regresszió",
    "text": "9.1 Egyszerű lineáris regresszió\n\nLegsokrétűbb statisztikai próba\nA legtöbb más statisztikai próbát regresszióként is lehet értelmezni\nCélja: a kimeneti változó értékeinek predikciója egy vagy több prediktor változó által\nAdat = model + error\n\nLineáris regresszió esetében a modellünk egy egyenes vonal\n\nAzt a lineáris modellt akarjuk megtalálni, ami legjobban illeszkedik az adatokra, ahol legkisebb a hiba\n\n\n9.1.1 Lineáris modell paraméterei\n\nMásnéven regressziós együtthatók (regression coefficients)\nMeredekség (slope): egy egységnyi változás a prediktor változóban (x tengely) mekkora változást okoz a kimeneti változóban (y tengely)\n\nHa pozitív érték, akkor pozitív kapcsolat van a két változó között\n\nHa a prediktor változónk értéke nő a kimeneti változó értéke is nő\n\nHa negatív érték, akkor negatív kapcsolat\n\nHa a prediktor változónk értéke nő, a kimeneti változónk értéke csökken\n\nJele: b1\n\nIntercept: ha a prediktor változó értéke 0, mekkora a kimeneti változó értéke, azaz milyen y értéknél metszi a vonal az y tengelyt\n\nJele: b0\n\n\n\n\n9.1.2 Lineáris modell illeszkedésének a vizsgálata\n\nHogyan találjuk meg azt a lineáris modellt, ami legjobban illeszkedik az adatokra?\n\nA legkisebb négyzetek módszere (method of least squares)\n\nMeghatározásához ugyanazt a módszert használhatjuk, mint amikor az átlagot használtuk, mint modellt\nMegnézzük a modell által prediktált értékek és a valós értékek közötti különbséget: a reziduálisokat (residuals)\nItt is négyzetre emeljük a reziduálisok majd összeadjuk őket (sum of squared differences, SS)\nEzután minden lehetséges vonalra (lineáris regressziós modellre) kiszámíthatnánk őket és ahol az SS a legkisebb az a modell illeszkedik a legjobban az adatokra\nAzonban még a legjobban illeszkedő modell is magyarázhatja rosszul az adatokat!\n\nAhhoz, hogy ezt megvizsgálájuk a legegyszerűbb modell illeszkedéséhez hasonlítjuk a regressziós modellunk illeszkedését: az átlaghoz\n\nAz átlag azonban minden adatpontra ugyanazt az értéket fogja prediktálni\n\nPéldául: mennyire számít a marketingre szánt összeg egy film összbevételénél?\n\nHa 1 dollárt költünk a marketingre akkor is ugyanazt a bevétlet prediktálja, mintha 200000$ költüttünk volna rá\n\n\nAz átlag modellnél a hibát összesítve megkapjuk a teljes négyzetösszeget (total sum of squares, SST)\n\nEz a teljes, mert ez a legegyszerűbb modell\n\nKiszámítjuk a négyzetre emelt reziduálisok összegét a regressziós modellnél is (residual sum of squares, SSR)\nAhhoz, hogy megtudjuk a regressziós modellünk mennyivel jobban magyarázza az adatokat, mint az átlag modellunk a kettőt kivonjuk egymásból: SST - SSR = SSM (model sum of squares)\n\nHa az SSM nagy, a regressziós modell sokkal jobban magyarázza az adatokat, mint az átlag\n\nMegnézhetjük, hogy arányosan mennyivel javul a modellünk az átlaghoz képest, ha egy prediktor változót is belerakunk\n\nA kettőt elosztva egymással megkapjuk a determinisztikus együtthatót R2\n\nSSM / SST\n\nMegmutatja a regressziós modellünk által megmagyarázott variancia arányát a kimeneti változónkban, a teljes varianciához képest\nHa megszorozzuk 100-al százalékot kapunk\nA kimeneti változóban lévő varianciának hány százalékát magyarázza meg a modell\nHa ennek a négyzetgyökét vesszük, akkor megkapjuk a Pearson korrelációs együtthatót!\n\nAz F-teszttel is megvizsgálhatjuk a modellünk illeszkedését\n\nF teszt statisztika: szisztematikus variancia / nem szisztematikus variancia\n\nA modell okozta javulás (SSM) / a modell és a megfigyel adatok között lévő különbség (SSR)\n\nMásszóval az F teszt statisztika megmondja, hogy a modell mennyire javítja a becslésünk pontosságát a modellben található pontatlansághoz képest\nItt nem a négyzetes különbségek összegével, hanem átlagával dolgozunk\n\nÍgy nem függ a megfigyelések számától\n\nMean squares for the model (MSS)\n\nSzabadságfok: prediktor változók száma\n\nResiduals mean square (MSR)\n\nSzabadságfok: megfigyelések száma - béta együtthatók száma (meredség + intercept = 2)\n\nJó modellnél 1-nél nagyobb az F arány\np-értéket vagy konfidencia intervallumot is ki tudunk hozzá számolni\n\n\n\n\n\n\n9.1.3 Prediktor változók szignifikanciájának vizsgálata\n\nNemcsak a teljes modell teljesítményét kell megvizsgálnunk, hanem az egyes paramétereknek a szignifikanciáját is\nA béta megmutatja, hogy a prediktorban való egy egységnyi változás mekkora változást okoz a kimeneti változóban\n\nHa a modell rossz, azt várjuk el, hogy ez nulla legyen\n\nPont, mint az átlagnál!\n\n\nA nullhipotézis a paraméterek esetén az lesz, h a paraméter nem különbözik a nullától\nA kritikus érték pedig a paraméter tényleges értéke\nEzekre gyakorlatilag egy egymintás t-próbát fogunk végezni\n\nt = béta / SE\n\nAz intercept esetén, hogy különbözik-e a nullától az érték.\nA slope esetén, hogy a dőlésszöge különbözik-e a nullától."
  },
  {
    "objectID": "regression.html#lineáris-regresszió-előfeltételei",
    "href": "regression.html#lineáris-regresszió-előfeltételei",
    "title": "9  Lineáris regresszió",
    "section": "9.2 Lineáris regresszió előfeltételei",
    "text": "9.2 Lineáris regresszió előfeltételei\n\nA kimeneti változó folytonos azaz legalább intervallum mérési szintű\nPrediktor típusok: folytonos vagy kategorikus is lehet\nNem zéró variancia: a kimeneti változó és prediktor értékeiben van variabilitás\nA megfigyelések egymástól függetlenek\nA reziduálisok eloszlása normális (a prediktor eloszlásának nem kell normálisnak lennie!)\n\nVizuálisan: \n\nQQ plot\n\nA pontok maradjanak az átló közelében\n\nAz esetek 5%-a lehet 2 szóráson kívül\nAz esetek 1%-a lehet 2.5 szóráson kívül\nAz esetek 0.1%-a lehet 3 szóráson kívül\n\n\nResidual vs fitted values\n\nResiduális értékek vannak az y tengelyen\nModell értékek az x tengelyen\nHa a vonal görbül, nem lineáris kapcsolat\n\n\n\nAz értékek\n\n68%-a egy szóráson belül van\n95%-a két szóráson belül van\n99.7%-a három szóráson belül van\n\nEhhez kapcsolódik, hogy a modellben nincsen sok jelentős kiugró érték (outlier), ami torzítja a modellünket\nAzt várjuk, hogy a lineáris regresszió minden mérési szinten ugyanannyira jó predikciót tudjon adni. Azaz, ugyanolyan hatékony legyen akkor, ha a buszmegállóban 3 ember van, mint akkor, ha 20\nEzt a reziduálisok elemzésével tudjuk ellenőrizni\nEkkor azt mondjuk, hogy a modellünk homoszkedasztikus, azaz a reziduálisok mértéke független a prediktor értékétől.\nEllentéte a heteroszkedaszticitás, ami azt jelenti, hogy pl. a kisebb prediktált értékekhez tartozó reziduálisok kisebbek, mint a nagyobb prediktált értékekhez tartozó reziduálisok\nVizsgálata vizuálisan zajlik\n\nTölcsér alak azt jelenti hogy sérül a heteroszkedaszticitás feltétle\n\nKiugró értékek szűrése\n\nVizuálisan\n\nTávol esnek a többi értéktől\nMagukhoz húzzák a regressziós egyenest\n\nStatisztikai módszerekkel\n\nCook’s distance\nHa 1-nél nagyobb erős torzító hatása van az adatpontnak\n\nMit tegyünk ha vannak outlierek?\n\nCsak akkor zárjuk ki ha adathibából származnak\nKülönben overfitting veszélye fennáll\n\nNagy elemszánál nem olyan nagy a hatásuk!\n\n9.3 Többszörös lineáris regresszió\n\nTovábbi tényezőkről is gondolhatjuk, hogy javítani fognak a modellünkön\n\nEgy bizonyos pont után, ha ezeket a prediktor változókat hozzáadjuk a modellhez, nem fog a hiba szignifikánsan csökkenni\nEz az overfitting\nEredménye: a modell nem lesz generalizálható"
  },
  {
    "objectID": "comparing_means.html#a-t-próba-típusai",
    "href": "comparing_means.html#a-t-próba-típusai",
    "title": "10  Két csoport átlagának összehasonlítása",
    "section": "10.1 A t-próba típusai",
    "text": "10.1 A t-próba típusai"
  },
  {
    "objectID": "comparing_means.html#a-t-próba-logikája",
    "href": "comparing_means.html#a-t-próba-logikája",
    "title": "10  Két csoport átlagának összehasonlítása",
    "section": "10.2 A t-próba logikája",
    "text": "10.2 A t-próba logikája\n\nKét mintát veszünk, ahol a mintáink lehetőleg csak az átlalunk vizsgált független változó mentén különböznek szisztematikusan\n\nPl: A) csoport tagjai részt vettek egy képzésen b) csoport tagjai nem vettek rész a képzésen (kontroll csoport)\n\nCélunk, hogy a csoport tagjai lehetőleg minden másban hasonlóak legyenek\n\nNe legyen olyan esetleges torzító faktor (például A) csoportba csak magas IQ-val rendelkező személyek vannak), ami torzíthatja a vizsgált hatást (a képzés hatására jobb pontot érnek-e el a személyek egy teszten)\n\n\n\nA null hipotézis alatt azt várjuk el, hogy a két minta átlagai között nem lesz különbség, a csoportok átlagainak különbsége a függő változóban a nulla körül helyezkedik el\n\nEbben az esetben a két minta feltételezhetően ugyanabból a populációból származik\n\nA megfigyelt minták átlagainak különbségét ahhoz a hipotetikus különbség értékhez hasonlítjuk, amit akkor várnánk el, ha nincs hatás (tehát a null hipotézis igaz)\nA standard hibát használjuk arra, hogy megvizsgáljuk a minta átlagok közti variabilitást\n\nHa a standard hiba kicsi akkor várhatóan a minta átlagok hasonlóak lesznek\nHa a standard hiba nagy akkor várhatóan nagy különbségek is előfordulhatnak a minta átlagok között\nMég akkor is, ha ugyanabból a populációból származnak\n\nHa a megfigyelt minta átlagok közti különbség nagyobb, mint amit elvárnánk a standard hiba alapján, ha a null hipotézis igaz, akkor feltételezhetjük:\n\nA valóságban nincs hatás, a két minta átlag ugyanabból a populációból származik, csak atipikus egyedei annak\n\nMásszóval: távol helyezkednek el a populáció átlagtól\n\nA valóságban van hatás, a null hipotézist elvetjük, a két minta valójában két különböző populációból származik, amelyeknek tipikus tagjai\n\nMásszóval a minta átlagok közel vannak a populációk átlagához, amiből származnak\n\n\nMinél nagyobb a hatás és minél kisebb a standard hiba, annál biztosabbak vagyunk benne, hogy a hatás valóban létezik"
  },
  {
    "objectID": "comparing_means.html#t-próba-mint-stasztikai-modell",
    "href": "comparing_means.html#t-próba-mint-stasztikai-modell",
    "title": "10  Két csoport átlagának összehasonlítása",
    "section": "10.3 t-próba, mint stasztikai modell",
    "text": "10.3 t-próba, mint stasztikai modell\n\nEgy teszt statisztikára gondolhatunk úgy is, mint a variancia, amit megmagyaráz a modellunk elosztva a varianciával, amit nem magyaráz meg a modellünk\n\nhatás / hiba\n\nt-próba esetében a statisztikai modell a két csoport átlagainak a különbsége\nA hiba mutatónk a standard hiba\n\nMegmutatja mennyire fluktuálnak a minta átlagok a mintevételezési hibának következtében\nEzt is az átlagok különbségére számoljuk ki"
  },
  {
    "objectID": "comparing_means.html#t-próba-előfeltételei",
    "href": "comparing_means.html#t-próba-előfeltételei",
    "title": "10  Két csoport átlagának összehasonlítása",
    "section": "10.4 t-próba előfeltételei",
    "text": "10.4 t-próba előfeltételei\n\nA változók legalább intervallum skálájúak\n\nEz az előfeltétele, hogy átlagot tudjunk számolni\n\nA mintavételei eloszlás (sampling distribution) normáls eloszlást követ\n\nA mintavételi eloszlást nem tudjuk közvetlenül megvizsgálni ezért azt nézzük meg, hogy a változók eloszlása normál eloszlást követ-e\n\nA centrális határeloszlás elve miatt feltételezzük\n\nha a változónk eloszlása normális a mintavételi eloszlás is normális lesz\nIlletve sok megfigyelés esetén a mintavételezési eloszlás úgyis a normálishoz közelít\n\n\nPáros t-próba esetén a két csoport értékeinek a különbsége kell normál eloszlást kövessen!\n\nFüggetlen mintás t-próba\n\nAz előfeltételeket tesztelni kell mielőtt a parametrikus Student t-próbát alkalmazhatnánk\nAz előző feltételeken felül:\n\nA különböző csoportokból származó értékek függetlenek egymástól\nSzórás homogenitás: a két csoport szórása hasonló"
  },
  {
    "objectID": "comparing_means.html#t-próba-eredményeinek-ábrázolása",
    "href": "comparing_means.html#t-próba-eredményeinek-ábrázolása",
    "title": "10  Két csoport átlagának összehasonlítása",
    "section": "10.5 t-próba eredményeinek ábrázolása",
    "text": "10.5 t-próba eredményeinek ábrázolása\n\nHegedű ábrával (violin plot)\nBarchart-tal\nNe feledkezzünk meg az error bar-ról!\n\nEz általában a standard hiba (SE)"
  }
]